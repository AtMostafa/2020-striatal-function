{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import KWIKphy\n",
    "import sys, pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, itertools\n",
    "# from KWIKphy.session import Session\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading raw spike data\n",
    "\n",
    "#### Paths: same as behavior\n",
    "\n",
    "#### Acquisition parameters (integers or floats):\n",
    "  - **amplification**: voltage amplification\n",
    "  - **nbits**: floats in .dat file are stored on nbits\n",
    "  - **nChannels**: total number of channels, needed to read .dat file\n",
    "  - **offset**: always 0\n",
    "  - **spikeSamplingRate**: number of acquisition per seconds for the spikes   \n",
    "    other names: SampleRate, sample_rate   \n",
    "  - **voltageRange**\n",
    "  \n",
    "#### Other\n",
    "  - **channelGroupList**: dictionary of channel groups (shank), ex: {1: [0,1,2,3,4,...], 2: [8,9,..], ..}\n",
    "  - **clusterGroup**: dictionary {channel_group: cluster_group}  \n",
    "       with cluster_group a dictionnary {\"Good\":[list of clu],\"Noise\":[List of clu],\"MUA\":...,\"Unsorted\":...}   \n",
    "  \n",
    "#### Nested dictionary { channelGroup: { clu : 1D numpy array} }  \n",
    "    For each channelGroup, a dictionary  \n",
    "    In this dictionary, for each clu, the list of the spike times or spike sample\n",
    "    \n",
    "   - **spikeSample**: sample of the spikes\n",
    "   - **spikeTime**: sample/spikeSamplingRate \n",
    "   - **spikeIndex**: index in the list, usefull to get waveform In .kwx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_RawSpikeData:\n",
    "    \n",
    "    def __init__(self,rootFolder,experiment,parameters={},saveAsPickle=True):             \n",
    "        self.root=os.sep+rootFolder.strip(os.sep)\n",
    "        self.experiment=experiment.strip(os.sep)\n",
    "        self.session=self.experiment\n",
    "        self.animal=experiment[:6]\n",
    "        \n",
    "        #paths\n",
    "        self.sessionPath=os.path.join(self.root,self.animal,\"Experiments\",self.experiment)\n",
    "        self.fullPath=os.path.join(self.root,self.animal,\"Experiments\",self.experiment,self.experiment)\n",
    "        \n",
    "        #check if every file is available, add them to the self\n",
    "        self._add_files()\n",
    "        \n",
    "        #parameters dict\n",
    "        self.parameters=parameters #dictionnary with \n",
    "        acquisitionParameters=self.read_acquisitionSystem_parameters()\n",
    "        for key in acquisitionParameters:\n",
    "            self.__dict__[key]=acquisitionParameters[key]\n",
    "        acquisitionParameters.update(self.parameters)\n",
    "                \n",
    "        self.channelGroup = self.read_probe()\n",
    "        \n",
    "        if saveAsPickle:\n",
    "            self.save_as_pickle()\n",
    "        \n",
    "    def _add_files(self,files=['prm','prb','kwik','evt.cam','evt.tre']):\n",
    "        \n",
    "        for file in files:\n",
    "            assert isinstance(file,str), 'file types must be a string'\n",
    "            key=file.replace('.','')+'File'\n",
    "            self.__dict__.update({key:self.fullPath+'.'+file})\n",
    "            if not os.path.isfile(self.__dict__[key]):\n",
    "                self.__dict__[key]=False\n",
    "\n",
    "    def read_acquisitionSystem_parameters(self):\n",
    "        assert self.prmFile, \"No prm file\"\n",
    "        prm=self.prm_reader(self.prmFile)\n",
    "        defaultParam={\n",
    "            \"gain\":prm['voltage_gain'],\n",
    "            \"nBits\":prm['nbits'],\n",
    "            \"samplingRate\":prm['sample_rate'],\n",
    "            \"nChannels\":prm['nchannels']\n",
    "        }\n",
    "        return defaultParam               \n",
    "                \n",
    "    def get_dict(self):\n",
    "        return self.__dict__\n",
    "    \n",
    "    def save_as_pickle(self,folder=\"Analysis\",name=\"rawspikedata.p\"):\n",
    "\n",
    "        folderPath=os.path.join(self.sessionPath,folder)\n",
    "        if not os.path.exists(folderPath):\n",
    "            os.mkdir(folderPath)\n",
    "        filePath=os.path.join(folderPath,name)\n",
    "        with open(filePath, \"wb\" ) as file:\n",
    "            pickle.dump(self, file)\n",
    "        \n",
    "    def read_probe(self):\n",
    "        \"\"\"\n",
    "        read channels number for each group (shank)\n",
    "        \"\"\"\n",
    "        assert self.prbFile, \"No prb file\"\n",
    "        prb=self.prm_reader(self.prbFile)\n",
    "        return prb['channel_groups']\n",
    "    \n",
    "    @staticmethod\n",
    "    def prm_reader(prmFile):\n",
    "        CWD=os.getcwd()\n",
    "        try:\n",
    "            os.chdir(os.path.dirname(prmFile))\n",
    "            prmName=os.path.basename(prmFile)\n",
    "            %run $prmName\n",
    "        finally:\n",
    "            os.chdir(CWD)\n",
    "        return globals()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Klusta+Phy spike data (**.kwik*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unit:\n",
    "    \"\"\"\n",
    "    This class is to implement the basic data structures for detected clusters\n",
    "    klusta: an instance of the KlustaRawSpikeData class\n",
    "    \"\"\"\n",
    "    \n",
    "    #locking new attribute creation other than those stated below\n",
    "    __slots__=('spikeSamples','type','shank','channels','NSpikes','id')\n",
    "    \n",
    "    def __init__(self,spikeTimes, cluType, cluChGroup, cluCh=-1, cluId=-1):\n",
    "        if not isinstance(spikeTimes,np.ndarray):\n",
    "            self.spikeSamples=np.asarray(spikeTimes)\n",
    "            assert self.spikeSamples.ndim <=2, \"spikeTime must be a 1D vector\"\n",
    "            if self.spikeSamples.ndim==2:\n",
    "                assert 1 in self.spikeSamples.shape, \"spikeTime has bad structure\"\n",
    "        else:\n",
    "            self.spikeSamples=spikeTimes\n",
    "        self.type=cluType\n",
    "        self.shank=cluChGroup\n",
    "        self.channels=cluCh\n",
    "        self.NSpikes=len(self.spikeSamples)\n",
    "        self.id=cluId\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'<{self.type} unit containing {self.NSpikes} spikes>'\n",
    "\n",
    "\n",
    "class Klusta_RawSpikeData(Base_RawSpikeData):\n",
    "    '''\n",
    "    Data obtained with Klusta\n",
    "    And curated with phy\n",
    "    4 default group: noise(0), MUA(1), Good(2) and Unsorted(3)\n",
    "       User could have created new groups (>=4), but I didn't find the new names in the kwik file. \n",
    "       So new groups are merged with Good\n",
    "    '''\n",
    "    def __init__(self,*args,**kwargs):\n",
    "        super().__init__(*args,**kwargs)\n",
    "        assert self.kwikFile, 'No kwik file'\n",
    "        \n",
    "        #Reading spiking data off the kwik file\n",
    "        self.read_spikes_sample_and_clu()\n",
    "    \n",
    "    #2 Following methods are defined because original class was not pickle-able\n",
    "    #============================================\n",
    "    def __getstate__(self):\n",
    "        state = self.__dict__.copy()\n",
    "        # Remove the unpicklable entries.\n",
    "        del state['kwikSession']\n",
    "        return state\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        # Restore instance attributes (\n",
    "        self.__dict__.update(state)\n",
    "        # Restore the previously removed entries\n",
    "        self.kwikSession= Session(self.kwikFile)\n",
    "    #=============================================\n",
    "    \n",
    "    def read_acquisitionSystem_parameters(self):\n",
    "        \n",
    "        self.kwikSession= Session(self.kwikFile)\n",
    "        \n",
    "        try:\n",
    "            param={\n",
    "                \"gain\":              self.kwikSession.model.metadata['voltage_gain'],\n",
    "                \"nBits\":             self.kwikSession.model.metadata[\"nbits\"],\n",
    "                \"samplingRate\":      self.kwikSession.model.sample_rate,\n",
    "                \"voltageRange\":      self.kwikSession.model.metadata[\"voltage_gain\"],\n",
    "                \"nChannels\":         self.kwikSession.model.metadata[\"n_channels\"]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(self.session,\"Failure to find info in the kwik file, loading from prmFile\")\n",
    "            print(repr(e))\n",
    "            param=super().read_acquisitionSystem_parameters()\n",
    "        \n",
    "        return param \n",
    "           \n",
    "    def read_spikes_sample_and_clu(self):\n",
    "        #chgroup is channel group (shank)\n",
    "        #cluGroup is the group of the cluster (noise, mua, good...)\n",
    "        self.is_curated= False\n",
    "        spikeSample,clusterGroup,unitDict={},{},{}\n",
    "        spikeIndex= {}\n",
    "        first= True\n",
    "        for chgroup in self.kwikSession.model.channel_groups:\n",
    "            if first:\n",
    "                first= False\n",
    "            else:\n",
    "                self.kwikSession.change_channel_group(chgroup)\n",
    "            unitDict[chgroup]=[]\n",
    "            clusterGroup[chgroup]={}\n",
    "\n",
    "            #default cluster group names (0: 'Noise', 1: 'MUA', 2: 'Good', 3: 'Unsorted')\n",
    "            for cluGroupName in self.kwikSession.model.default_cluster_groups.values():\n",
    "                clusterGroup[chgroup][cluGroupName]=[]\n",
    "            \n",
    "            #for every cluster in the channel_group\n",
    "            for clu in self.kwikSession.model.cluster_ids:\n",
    "                if clu == 0:\n",
    "                    continue\n",
    "                spikeSample=self.kwikSession.model.spike_samples[self.kwikSession.model.spike_clusters==clu]  \n",
    "                cluGroupID=self.kwikSession.model.cluster_metadata.group(clu)\n",
    "                if isinstance(cluGroupID, np.ndarray):\n",
    "                    print(\"Warning- cluster group of cluster %s is an array (%s), taking first value\"%(clu,cluGroupID))\n",
    "                    cluGroupID=cluGroupID[0]\n",
    "                if isinstance(cluGroupID, bytes):\n",
    "                    print(\"Warning- cluster group of cluster %s is a bytes, putting it in 'unsorted'\"%(clu))\n",
    "                    cluGroupID = 3\n",
    "                # if a group was created (ID>3), put it in \"Good\"(2)\n",
    "                if cluGroupID>3:\n",
    "                    cluGroupID=2\n",
    "                cluGroupName=self.kwikSession.model.default_cluster_groups[cluGroupID]        \n",
    "                clusterGroup[chgroup][cluGroupName].append(clu)\n",
    "                \n",
    "                unit=Unit(spikeTimes=spikeSample, cluType=cluGroupName, cluChGroup=chgroup, cluId=clu)\n",
    "                unitDict[chgroup].append(unit)\n",
    "                if cluGroupID != 3: #if the cluster is not unsorted\n",
    "                    self.is_curated= True\n",
    "       \n",
    "        self.unitDict=unitDict\n",
    "    \n",
    "    def typed_units(self):\n",
    "        \"\"\"\n",
    "        This function returns a dict of units\n",
    "        ordered by their type (Good, Noise,...)\n",
    "        \"\"\"\n",
    "        typedUnits={}\n",
    "        for unit in itertools.chain.from_iterable(self.unitDict.values()):\n",
    "            try:\n",
    "                typedUnits[unit.type].append(unit)\n",
    "            except KeyError:\n",
    "                typedUnits[unit.type]=[unit]\n",
    "        return typedUnits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#run only if inside this notebook (do not execute if \"%run this_notebook\")\n",
    "if \"__file__\" not in dir():\n",
    "    root=\"/data\"\n",
    "    experiment=\"Rat173_2018_02_25_12_03\"\n",
    "\n",
    "    data=Klusta_RawSpikeData(root,experiment,saveAsPickle=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
