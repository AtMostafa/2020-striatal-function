{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook run code(s) on multiple animal/session/ for RAT Behavioral experiment\n",
    "\n",
    "### This notebook is at the core of the pipeline of data processing. Do not play with it lightly inside the master folder (load_preprocess_rat)\n",
    "\n",
    "#### 1. Only modifiy if you are sure of what you are doing and that you are solving a bug\n",
    "#### 2. If you do modify you MUST commit this modification using bitbucket\n",
    "#### 3. If you want to play whis notebook (to understand it better) copy it on a toy folder distinct from the master folder\n",
    "#### 4. If you want to modify this code (fix bug, improve, add attributes ...) it is recommanded  to first duplicate in a draft folder. Try to keep track of your change.\n",
    "#### 5. When you are ready to commit : # clear all output, clean everything between hashtag \n",
    "\n",
    "\n",
    "\n",
    "## 1. Load packages and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modules to find path of all sessions\n",
    "import glob\n",
    "import os, logging\n",
    "import gc\n",
    "import numpy as np\n",
    "from IPython.display import clear_output, display, HTML, Image\n",
    "import matplotlib.cm as cm\n",
    "from platform import system as OS\n",
    "from multiprocessing import Pool, Process\n",
    "import threading\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys, shutil\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "#run other notebooks\n",
    "\n",
    "# The lines below allow to run required notebook from the master folder\n",
    "if \"__file__\" not in dir():\n",
    "    \n",
    "    ThisNoteBookPath=os.path.dirname(os.path.realpath(\"__file__\"))\n",
    "    CommonNoteBookesPath=os.path.join(os.path.split(ThisNoteBookPath)[0],\"load_preprocess_rat\")\n",
    "    CWD=os.getcwd()\n",
    "    os.chdir(CommonNoteBookesPath)\n",
    "    %run UtilityTools.ipynb\n",
    "    %run Animal_Tags.ipynb\n",
    "    %run loadRat_documentation.ipynb\n",
    "    %run plotRat_documentation_1_GeneralBehavior.ipynb\n",
    "    %run plotRat_documentation_3_KinematicsInvestigation.ipynb\n",
    "    os.chdir(CWD)\n",
    "\n",
    "    # PARAMETERS (used if the pickles don't exist)\n",
    "    param={\n",
    "        \"goalTime\":7,#needed for pavel data only\n",
    "        \"treadmillRange\":[0,90],#pavel error conversion \"treadmillRange\":[0,80]\n",
    "        \"maxTrialDuration\":15,\n",
    "        \"interTrialDuration\":10,#None pavel\n",
    "        \"endTrial_frontPos\":30,\n",
    "        \"endTrial_backPos\":55, \n",
    "        \"endTrial_minTimeSec\":4,\n",
    "        \"cameraSamplingRate\":25, #needed for new setup    \n",
    "\n",
    "        \"sigmaSmoothPosition\":0.1,#0.33, 0.18 pavel\n",
    "        \"sigmaSmoothSpeed\":0.3,#0.3, 0.5 pavel\n",
    "        \"nbJumpMax\":100,#200 pavel\n",
    "        \"binSize\":0.25,\n",
    "        #parameters used to preprocess (will override the default parameters)\n",
    "    }  \n",
    "\n",
    "    if OS()=='Linux':\n",
    "        root=\"/data\"\n",
    "    elif OS()=='Windows':\n",
    "        root=\"C:\\\\DATA\\\\\"\n",
    "    else:\n",
    "        root=\"/Users/davidrobbe/Documents/Data/\"\n",
    "        \n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "    print('os:',OS(),'\\nroot:',root,'\\nImport successful!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_or_read_stats(data, PerfParamToPlot, \n",
    "                          saveAsPickle=True, pickleName=\"behaviorStats.p\",redo=False):\n",
    "    \"\"\"\n",
    "    Function to calculate the performance parameters of a single session\n",
    "    \"\"\"\n",
    "    pathPickle=os.path.join(data.analysisPath,pickleName)\n",
    "    if os.path.exists(pathPickle) and not redo:\n",
    "        with open(pathPickle,\"rb\") as f:\n",
    "            result=pickle.load(f)\n",
    "            if set(PerfParamToPlot).issubset(set(result.keys())):\n",
    "                result={key:result[key] for key in result.keys() if key in PerfParamToPlot}\n",
    "                return result\n",
    "            else:\n",
    "                params=list(set(PerfParamToPlot).difference(set(result.keys())))\n",
    "                result={key:result[key] for key in result.keys() if key not in params}\n",
    "            f.close()\n",
    "    else:\n",
    "        params=PerfParamToPlot\n",
    "        result={}\n",
    "    for param in params:\n",
    "        try:\n",
    "            if param==\"% good trials\":\n",
    "                #percentage of good trials\n",
    "                result[param]=np.round(len(data.goodTrials)/(float(data.nTrial)+0) *100)\n",
    "            elif param==\"% good trials on last 40\":\n",
    "                #percentage of good trials in the 40 last trials\n",
    "                last40GoodTrial=[trial for trial in data.goodTrials if trial>(data.nTrial-41)]\n",
    "                result[param]=np.round(len(last40GoodTrial)/40.0 *100)\n",
    "            elif param==\"percentile entrance time\":\n",
    "                #percentile entrance time\n",
    "                realEntranceTimes=data.entranceTime[data.entranceTime<data.maxTrialDuration]\n",
    "                if len(realEntranceTimes)>0:\n",
    "                    entranceTimeP=np.nanpercentile(realEntranceTimes,[10,25,50,75,90])\n",
    "                    result[param]=entranceTimeP\n",
    "                else:\n",
    "                    result[param]=np.full(5,data.maxTrialDuration[0])\n",
    "            elif param==\"median entrance time (sec)\":\n",
    "                #median and std of entrance time\n",
    "                result[param]=np.nanmedian(data.entranceTime[data.entranceTime<data.maxTrialDuration])\n",
    "            elif param==\"standard deviation of entrance time\":    \n",
    "                result[param]=np.nanstd(data.entranceTime)\n",
    "            elif param==\"mean entrance time (sec)\":\n",
    "                result[param]=np.nanmean(data.entranceTime[data.entranceTime<data.maxTrialDuration])\n",
    "\n",
    "                #median correlation trajectories\n",
    "                #result[\"median correlation of trajectories\"]=plot_correlation_position(data,onlyGood=True)\n",
    "            elif param==\"spearman entrance time\":\n",
    "                #correlation entrance time\n",
    "                result[param]=plot_correlation_entrance_time(data)\n",
    "            elif param==\"time running forward\":\n",
    "                #proportion of time running forward\n",
    "                areaUnderCurve=plot_proportionTimeRunningForward_TrajEnd(data,binSize=1,minSpeed=-20,maxSpeed=120,smoothSpeed=0.3,onlyGood=False,highSpeed=None)\n",
    "                result[param]=areaUnderCurve\n",
    "            elif param==\"timerunningforwardGoodTrials\":\n",
    "                #proportion of time running forward for good trials\n",
    "                areaUnderCurve=plot_proportionTimeRunningForward_TrajEnd(data,binSize=1,minSpeed=-20,maxSpeed=120,smoothSpeed=0.3,onlyGood=True,highSpeed=None)\n",
    "                result[param]=areaUnderCurve\n",
    "            elif param==\"Forward Speed\":\n",
    "                #Forward Speed\n",
    "                result[param]=plot_mean_forwardSpeed(data,smoothSpeed=0.3,onlyGood=False)\n",
    "                plt.close()\n",
    "            elif param==\"Forward Speed Vs TreadmillSpeed\":\n",
    "                #Forward Speed vs TreadmillSpeed\n",
    "                result[param]=plot_mean_forwardSpeedVsTreadmillSpeed(data,smoothSpeed=0.3,onlyGood=False)\n",
    "                plt.close()\n",
    "            elif param==\"Forward Speed good trials\":\n",
    "                #Forward Speed for good trials\n",
    "                result[param]=plot_mean_forwardSpeed(data,smoothSpeed=0.3,onlyGood=True)\n",
    "                plt.close()\n",
    "            elif param==\"Tortuosity\":\n",
    "                #Tortuosity  and StraightSpeedForward\n",
    "                SessionTortuosity,SessionStraightSpeed=plot_Tortuosity(data, onlyGood=False)\n",
    "                plt.close()\n",
    "                result[param]=SessionTortuosity\n",
    "            elif param==\"Straight Speed Forward\":\n",
    "                SessionTortuosity,SessionStraightSpeed=plot_Tortuosity(data, onlyGood=False)\n",
    "                plt.close()\n",
    "                result[param]=SessionStraightSpeed\n",
    "            elif param==\"Trajectory Correlation\":\n",
    "                #Trajectory Correlation\n",
    "                SessionCorrelationTrajectory= plot_correlation_position(data,onlyGood=False,raw=False)\n",
    "                plt.close()\n",
    "                result[param]=SessionCorrelationTrajectory\n",
    "            elif param==\"Trajectory Correlation good trials\":\n",
    "                #Trajectory Correlation for good trials\n",
    "                SessionCorrelationTrajectory= plot_correlation_position(data,onlyGood=True,raw=False)\n",
    "                plt.close()\n",
    "                result[param]=SessionCorrelationTrajectory\n",
    "            elif param==\"Std from goaltime\":\n",
    "                #Std from goaltime\n",
    "                result[param]=std_from_goaltime(data)\n",
    "            elif param==\"Delivered Reward Ratio\":\n",
    "                result[param]=data.deliveredRewardRatio\n",
    "            elif param==\"Number of missed trials\":\n",
    "                result[param]=sum(data.entranceTime<0.1)+sum(data.entranceTime>data.maxTrialDuration-1)\n",
    "            elif param==\"Mean Pairwise RMSE\":\n",
    "                m,_=plot_rmse(data,alignedOnBegining=True,onlyGood=False,raw=False)\n",
    "                result[param]=m\n",
    "            elif param==\"Entropy\":\n",
    "                _,H=plot_trajectory_PDF(data,TimeRes=.5,PosRes=5,onlyGood=False)\n",
    "                plt.close()\n",
    "                result[param]=H\n",
    "            elif param==\"Run Distance\":\n",
    "                dis=plot_run_distance(data)\n",
    "                plt.close()\n",
    "                result[param]=np.mean(dis)\n",
    "            elif param==\"Intertrial Displacement\":\n",
    "                dis=intertrial_displacement(data)\n",
    "                result[param]=np.mean(dis)\n",
    "            elif param==\"Forward Running Speed\":\n",
    "                speed=forwardRunningSpeed(data).compute()\n",
    "                result[param]=np.mean(list(speed.values()))\n",
    "                plt.close()\n",
    "            elif param==\"Forward Running Speed on Last 40\":\n",
    "                speed=forwardRunningSpeed(data)\n",
    "                speed.conditions(last_n=40)\n",
    "                speed=speed.compute()\n",
    "                result[param]=np.mean(list(speed.values()))\n",
    "            elif param==\"Forward Running Speed on First 40\":\n",
    "                speed=forwardRunningSpeed(data)\n",
    "                speed.conditions(first_n=40)\n",
    "                speed=speed.compute()\n",
    "                result[param]=np.mean(list(speed.values()))\n",
    "            elif param==\"Lick Onset Delay\":\n",
    "                lickTrdStop=plot_lick_raster(data,plot_inset=False)\n",
    "                plt.close()\n",
    "                posLicks=[np.array(lick)[np.array(lick)>0] for i,lick in enumerate(lickTrdStop)\n",
    "                          if len(lick)>0 and i in data.goodTrials]\n",
    "                firstLick=[i[0] for i in posLicks if len(i)>0]\n",
    "                result[param]=np.mean(firstLick)\n",
    "            elif param==\"Entrance Time MSE\":\n",
    "                et=data.entranceTime\n",
    "                et=et[et != data.maxTrialDuration.mean()]\n",
    "                result[param]=np.sum((et-data.goalTime.mean())**2)/len(et)\n",
    "            elif param==\"Number of Very Bad Trials\":\n",
    "                result[param]=sum(data.entranceTime<3)\n",
    "            elif param==\"Successive Entrance Score\":\n",
    "                result[param]=correct_succession_score(data, etRange=(6,10), minSuccession=3)\n",
    "            elif param==\"Motor Sequence Score\":\n",
    "                seqObj=sequentialTrials(data)\n",
    "                seq_score= seqObj.SeqScore()\n",
    "                result[param]=seq_score\n",
    "            elif param==\"Waiting Time\":\n",
    "                seqObj=sequentialTrials(data)\n",
    "                wait_time= seqObj.WaitingTime()\n",
    "                result[param]=wait_time\n",
    "            elif param==\"Maximum Position\":\n",
    "                seqObj=sequentialTrials(data)\n",
    "                maxPos=seqObj.MaxPosition()\n",
    "                result[param]=maxPos\n",
    "            \n",
    "            else:\n",
    "                assert isinstance(param,str), 'Behavioral parameters must be /strings/'\n",
    "                result[param]=globals()[param](data)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(repr(e))\n",
    "            result[param]=np.nan\n",
    "    \n",
    "    if saveAsPickle:\n",
    "        with open(pathPickle, 'wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "            f.close()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learningCurves(root,animal,PerfParamToPlot,profile,\n",
    "                        stop_date='',parameter={},\n",
    "                        redoPreprocess=False, redoStat=False,override=False,plot=True,PrintWarning=False):\n",
    "    results={}\n",
    "    days=[]\n",
    "    indexSession=[]\n",
    "    events=[]\n",
    "    errorSession=[]\n",
    "    if animal=='':\n",
    "        sessionProfile=batch_get_session_list(root,animalList=[],profile=profile,until_date=stop_date)\n",
    "        if sessionProfile=={}:\n",
    "            print('bad settings!')\n",
    "            return False\n",
    "        sessionList=sessionProfile['Sessions']\n",
    "        animal=sessionList[0][:6]   #needs revision when needed!\n",
    "    else:\n",
    "        AnimalTagPath=os.path.join(root,animal,animal+'.tag')\n",
    "        if not os.path.isfile(AnimalTagPath):\n",
    "            print('No tag file for ',animal)\n",
    "            return False\n",
    "\n",
    "        #Get the list of good! sessions\n",
    "        sessionProfile=get_session_list(AnimalTagPath,profile=profile,until_date=stop_date)\n",
    "        sessionList=sessionProfile['Sessions']\n",
    "        if sessionList==[] or sessionProfile=={}:\n",
    "            print(animal,': Bad Tag file!')\n",
    "            return False\n",
    "    res_TS =[]\n",
    "    #loop through sessions\n",
    "    for session in sessionList:\n",
    "        try:\n",
    "            sessionData=Data(root,animal,session,parameter,redoPreprocess=redoPreprocess)\n",
    "        except Exception as e:\n",
    "            if PrintWarning:\n",
    "                display(HTML(\"<b> An error happened, skip session. Error message: </b>\"))\n",
    "                display(HTML(\"<b>\"+e.__class__.__name__+\": \"+str(e)+\"</b>\"))\n",
    "                print(\"--------\")\n",
    "            \n",
    "            errorSession.append(session)\n",
    "            continue\n",
    "        \n",
    "        #---skip if file \"NotToAnalyze\"\n",
    "        try:\n",
    "            if \"NotToAnalyze\" in sessionData.emptyAnalysisFiles:\n",
    "                if PrintWarning:\n",
    "                    print(\"Not to analyze, skipped\")\n",
    "                    print(\"--------\")\n",
    "                continue \n",
    "        except:\n",
    "            continue\n",
    "           \n",
    "        try :\n",
    "            et=sessionData.entranceTime \n",
    "        except:\n",
    "            if PrintWarning:\n",
    "                print('No entrance time, skipped')\n",
    "                print(\"--------\")\n",
    "            continue   \n",
    "        #skip if training data or no break time\n",
    "        if (not sessionData.hasBehavior):\n",
    "            if PrintWarning:\n",
    "                print(\"No Behavior, skipped\")\n",
    "                print(\"--------\")\n",
    "            continue\n",
    "        \n",
    "        #plot the png image in session folder\n",
    "        sessionData.plot_session_png_html([plot_session_behavior],override=override)\n",
    "\n",
    "        days.append(sessionData.daySinceStart)\n",
    "        events.append(sessionProfile['Event'][sessionList.index(session)])\n",
    "        events[-1]=events[-1] if len(events[-1]) >=3 else ''\n",
    "        eventDay=[days[i] for i,_ in enumerate(events) if events[i] != '']\n",
    "            \n",
    "        #Compute a bunch of Performance Parameters using a dedicated function\n",
    "        res=compute_or_read_stats(sessionData,PerfParamToPlot,redo=redoStat)\n",
    "        #--------------------session parameters---------------\n",
    "        #treadmill speed\n",
    "        uniqueTreadSpeed=np.unique(sessionData.treadmillSpeed)\n",
    "        if len(uniqueTreadSpeed)<len(sessionData.treadmillSpeed)*0.8:\n",
    "            res[\"treadmillSpeed\"]=scipy.stats.mode(sessionData.treadmillSpeed,nan_policy='omit')[0][0]\n",
    "        else:\n",
    "            res[\"treadmillSpeed\"]='var '\n",
    "        #goaltime. In some rare cases goaltime is NaN, as entrenace time was not written properly during data acquisition\n",
    "        res[\"goalTime\"]=np.unique(sessionData.goalTime[~np.isnan(sessionData.goalTime)])\n",
    "        if len(res[\"goalTime\"])>1:\n",
    "            res[\"goalTime\"]=np.median(res[\"goalTime\"])\n",
    "        \n",
    "        res[\"maxTrialDuration\"]=float(np.nanmax(sessionData.maxTrialDuration))\n",
    "               \n",
    "        keys = list(res.keys())\n",
    "        for key in keys:\n",
    "            try:\n",
    "                results[key].append(res[key])\n",
    "            except KeyError:\n",
    "                results[key]=[res[key]]\n",
    "    \n",
    "    \n",
    "    results[\"days\"]=days\n",
    "    results.update({'sessionProfile':sessionProfile})\n",
    "    # One subplot for every key in results\n",
    "    nbCol=2\n",
    "    nbLine=len(PerfParamToPlot)//nbCol+len(PerfParamToPlot)%nbCol\n",
    "    if plot:    \n",
    "        fig=plt.figure(figsize=(15, 3*nbLine))\n",
    "        #fig.subplots_adjust(hspace=1)\n",
    "        for index,key in enumerate(PerfParamToPlot):\n",
    "            ax=plt.subplot(nbLine,nbCol,index+1)\n",
    "            if key==\"percentile entrance time\":\n",
    "                med=[array[2] for array in results[key]]\n",
    "                lowestdist=[array[1] for array in results[key]]\n",
    "                higestdist=[array[-2] for array in results[key]]\n",
    "                lowError=[array[2]-array[1] for array in results[key]]\n",
    "                highError=[array[3]-array[2] for array in results[key]]\n",
    "                ax.errorbar(days,med,yerr=np.vstack([lowError,highError]),ls=\"\",color='k')\n",
    "                ax.scatter(days,med,c='k',zorder=10, s=20)\n",
    "                ax.plot(days,med,color=\"lightgrey\",linewidth=2)\n",
    "                #ymax=max(higestdist)\n",
    "                #ymin=min(lowestdist)\n",
    "                key+=\" (25% - 50% - 75%)\"\n",
    "                try:\n",
    "                    ax.set_ylim([0,max(results['maxTrialDuration'])])\n",
    "                except:\n",
    "                    ax.set_ylim([0,15])\n",
    "                \n",
    "                ax.plot(days,results[\"goalTime\"],color=\"red\",linestyle='--')\n",
    "            else:\n",
    "                ax.plot(days,results[key],color=\"lightgrey\",linewidth=2)\n",
    "                ax.scatter(days,results[key],c='k',zorder=10,s=20)\n",
    "                #ymax=max([x for x in results[key] if not isNone(x)])\n",
    "                #ymin=min([x for x in results[key] if not isNone(x)])\n",
    "           \n",
    "            for day in eventDay:\n",
    "                ax.axvline(day,color='m',linestyle='--')\n",
    "\n",
    "            ax.set_title(animal+\" \"+key)\n",
    "            ax.set_xlabel(\"session day\")\n",
    "            ax.xaxis.grid(which='major')  \n",
    "            \n",
    "#             if key==\"median entrance time (sec)\":\n",
    "#                 ax.set_ylim([0,15])\n",
    "#             if key==\"treadmillSpeed\":\n",
    "#                 ax.set_ylim([0,35])\n",
    "#             if key==\"Trajectory Correlation\":\n",
    "#                 ax.set_ylim([0,1])\n",
    "#             if key==\"% good trials on last 40\":\n",
    "#                 ax.set_ylim([0,100])   \n",
    "#                 plt.axhline(72.5,linestyle='--',color='red')\n",
    "#             if key==\"Forward Speed Vs TreadmillSpeed\":\n",
    "#                 ax.set_ylim([1,10])\n",
    "#             if key==\"Std from goaltime\":\n",
    "#                 ax.set_ylim([0,5])\n",
    "#             if key==\"Tortuosity\":\n",
    "#                 ax.set_ylim([0,10])\n",
    "\n",
    "            major_ticks = np.arange(0, days[-1], 10)                                              \n",
    "            minor_ticks = np.arange(0, days[-1], 2)                                               \n",
    "            ax.set_xticks(major_ticks)                                                       \n",
    "            #ax.set_xticks(minor_ticks, minor=True)\n",
    "            ax.set_xlim([days[0]-1,days[-1]+1])\n",
    "                 \n",
    "        plt.tight_layout()            \n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        #plot title\n",
    "        speed=sessionProfile['Speed'][sessionProfile['Type'].index('Good')]\n",
    "        tag  =sessionProfile['Tag'][sessionProfile['Type'].index('Good')]\n",
    "        Title=animal+': '+tag+'@'+str(speed)\n",
    "        for i,day in enumerate(eventDay):\n",
    "            speed=str(sessionProfile['Speed'][days.index(day)])\n",
    "            tag=sessionProfile['Tag'][days.index(day)]\n",
    "            Title+=' > '+tag+'@'+speed\n",
    "            if len(eventDay)>=5 and i%4==0:\n",
    "                Title+='\\n'\n",
    "        plt.suptitle(Title)\n",
    "\n",
    "        #save plot\n",
    "        animalAnalysisPath=os.path.join(root,animal,\"Analysis\")\n",
    "        fullPathLearningCurves=os.path.join(animalAnalysisPath,\"LearningCurves.png\")\n",
    "        LearningCurveName=os.path.basename(fullPathLearningCurves)\n",
    "        if not os.path.exists(animalAnalysisPath):\n",
    "            os.mkdir(animalAnalysisPath)\n",
    "        plt.savefig(fullPathLearningCurves)\n",
    "        plt.close('all')\n",
    "        del fig\n",
    "        \n",
    "        #Insert the learning curves png figure in the general HTML page that shows behavioral performance session by session(all_behavior_plot.html)        \n",
    "        nameGeneralHTML = \"all_plot_session_behavior.html\"\n",
    "        pathGeneralHTML = os.path.join(animalAnalysisPath, nameGeneralHTML)\n",
    "        LearningCurveImage= [\"<a href=#%s><center><img src='%s' alt='%s' title='LearningAcrossSession'/></center></a>\"%(animalAnalysisPath, LearningCurveName,fullPathLearningCurves)]#Line to add\n",
    "        sessionData.remove_lines_in_html(pathGeneralHTML, LearningCurveName) #remove the old LearningAcrossSession.png if there is one...\n",
    "        sessionData.insert_in_html(pathGeneralHTML, LearningCurveImage, nameGeneralHTML) #insert the new one at the end\n",
    "        \n",
    "        #save learning curve of all performance and task param in pickle\n",
    "        #saving happens ONLY if profile is empty (includes all the sessions)\n",
    "        if profile=={} or list(profile.keys())==['Type']:\n",
    "            path=os.path.join(root,animal,\"Analysis\")\n",
    "            if not os.path.exists(path):\n",
    "                    os.mkdir(path)\n",
    "            path=os.path.join(path,\"learningStats.p\")\n",
    "\n",
    "            with open(path, 'wb') as f:\n",
    "                pickle.dump(results, f)\n",
    "                f.close()\n",
    "            if PrintWarning:\n",
    "                print(\"Save pickle: %s\"%path)\n",
    "\n",
    "    if errorSession:\n",
    "        if PrintWarning:\n",
    "            display(HTML(\"<b> An error happened for the following session(s):\"))\n",
    "            print(\"\\n\".join(errorSession))\n",
    "    \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def animal_learning_stats(root: str, animal: str, PerfParam: str, profile: dict =None,\n",
    "                          sessionSlice=slice(0,None), goodSessions=None,\n",
    "                          newerThan=datetime.datetime.min, parameters={}, redo=False):\n",
    "    \"\"\"\n",
    "    returns behavioral stats for sessions described by:\n",
    "        1) 'profile' and 'sessionSlice' if necessary\n",
    "        2) directly giving the interesting sessions in a list called 'goodSessions'. 'profile' and 'sessionSlice' are ignored.\n",
    "    newerThan: specifies the date that the pickles must be newer thatn, or recalculated otherwise.\n",
    "    \n",
    "    this function handles pickles automatically.\n",
    "    PerfParam: must be a performance measure in a 'str'.\n",
    "    \"\"\"\n",
    "    out=[]\n",
    "    if goodSessions is None:\n",
    "        assert isinstance(profile,dict) and isinstance(sessionSlice,slice), 'Wrong type for profile/sessionSlice arguments.'\n",
    "        goodSessions=batch_get_session_list(root,animalList=[animal],profile=profile)['Sessions'][sessionSlice]\n",
    "    else:\n",
    "        assert isinstance(goodSessions,(list,tuple)), 'The \"goodSessions\"argument must be a list/tuple'\n",
    "    \n",
    "    pathPickle=os.path.join(root,animal,\"Analysis\",f\"{PerfParam}.p\")\n",
    "    if os.path.exists(pathPickle) and not redo:\n",
    "        with open(pathPickle,\"rb\") as f:\n",
    "            results=pickle.load(f)\n",
    "        try:\n",
    "            assert results['Date'] > newerThan, 'Pickle date is older than specified!'\n",
    "            sessionList=results['sessionProfile']['Sessions']\n",
    "            assert set(sessionList).issuperset(set(goodSessions)), 'Pickle data is incomplete.'\n",
    "            for session in goodSessions:\n",
    "                idx=sessionList.index(session)\n",
    "                out.append(results[PerfParam][idx])\n",
    "            return out\n",
    "        \n",
    "        except Exception as e:\n",
    "            logging.warning(repr(e))\n",
    "    \n",
    "    logging.info(f'{PerfParam} for {animal}...')\n",
    "    #in case no pickle or incomplete pickle\n",
    "    results= plot_learningCurves(root,animal,PerfParamToPlot=[PerfParam],profile={'Type':'Good'},\n",
    "                                 parameter=parameters,redoStat=redo,plot=False)\n",
    "    \n",
    "    sessionList=results['sessionProfile']['Sessions']\n",
    "    out=[]\n",
    "    for session in goodSessions:\n",
    "        try:\n",
    "            idx=sessionList.index(session)\n",
    "            out.append(results[PerfParam][idx])\n",
    "        except:\n",
    "            logging.error(f'failed:{animal}, {session}, {PerfParam}')\n",
    "            out.append(np.nan)\n",
    "        \n",
    "    PickDict={'sessionProfile':results['sessionProfile'],\n",
    "              PerfParam:results[PerfParam],\n",
    "             'Date':datetime.datetime.today()}\n",
    "    with open(pathPickle, 'wb') as f:\n",
    "        pickle.dump(PickDict, f)\n",
    "        f.close()\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "# if \"__file__\" not in dir():\n",
    "#     profileLesion={\n",
    "#         'Type':'Good',\n",
    "#         'rewardType':'Progressive',\n",
    "#         'option':['not used', 'AsymmetricLesion'],\n",
    "#         'initialSpeed':['10','0'],\n",
    "#         'Speed':'10',\n",
    "#         'Tag':['Late-Lesion_DLS','Late-Lesion_DMS','Late-Lesion_DMS-Sharp','Late-Lesion_DS','Late-Lesion_DS-Sharp']\n",
    "#         }\n",
    "#     animalList=batch_get_animal_list(root,profileLesion)\n",
    "    \n",
    "#     for animal in animalList:\n",
    "#         animal_learning_stats(root, animal, PerfParam=\"Forward Running Speed\", profile={'Type':'Good'}, redo=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define animalList, the function(s) you want to run in batch and redo(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    \n",
    "    #Define desired profile dictionary\n",
    "    AnimalProfile={'Type':'Good',\n",
    "         'rewardType':'Progressive',\n",
    "         'initialSpeed':['10'],\n",
    "         'Speed':'10',\n",
    "         'Tag':'Control'\n",
    "                  }\n",
    "\n",
    "    animalList=batch_get_animal_list(root,AnimalProfile)\n",
    "    print('animal list:',animalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "\n",
    "    animalList=get_current_animals(days_passed=5)\n",
    "#     animalList=['Rat162', 'Rat218', 'Rat263', 'Rat106', 'Rat229', 'Rat255', 'Rat232', 'Rat095', 'Rat161', 'Rat225', 'Rat131', 'Rat138', 'Rat132', 'Rat144', 'Rat221', 'Rat226', 'Rat250', 'Rat304', 'Rat305', 'Rat091', 'Rat284', 'Rat227', 'Rat254', 'Rat230', 'Rat163', 'Rat223', 'Rat113', 'Rat120', 'Rat141', 'Rat231', 'Rat256', 'Rat217', 'Rat302', 'Rat299', 'Rat085', 'Rat140', 'Rat301', 'Rat219', 'Rat139', 'Rat308', 'Rat164', 'Rat251', 'Rat252', 'Rat096', 'Rat137', 'Rat215', 'Rat224', 'Rat220', 'Rat260', 'Rat249', 'Rat300', 'Rat264', 'Rat222']\n",
    "    print(len(animalList),'animals:\\n',animalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    updateTagFiles = True   #update the outdated tag files, if needed (manual manipulation might be needed!)\n",
    "    redoPreprocess = False  #redo basic preprocess and generate Data. Otherwise load from pickle \n",
    "    redoStat = False         #regenerate performance measures\n",
    "    replaceHtml=False       #regenerate general HTML per animal. Otherwise use existing\n",
    "    override = False        #regenerate single session png figure. Otherwise use existing\n",
    "    plot=True\n",
    "    PrintWarning=False\n",
    "    PerfParamToPlot =[\"percentile entrance time\",'standard deviation of entrance time',\"% good trials on last 40\",\n",
    "                      \"Trajectory Correlation\",\"% good trials\",\"Mean Pairwise RMSE\",\"Forward Speed Vs TreadmillSpeed\",\n",
    "                      \"Tortuosity\",\"Run Distance\",\"Delivered Reward Ratio\",\"median entrance time (sec)\"]\n",
    "    PerfParamToPlot =[\"median entrance time (sec)\",\"percentile entrance time\",\"% good trials\",\n",
    "                      'standard deviation of entrance time',\"% good trials on last 40\",\n",
    "                      \"Trajectory Correlation\",\"Mean Pairwise RMSE\",\"Forward Speed Vs TreadmillSpeed\",\n",
    "                      \"Tortuosity\",\"Run Distance\",\"Delivered Reward Ratio\",\"mean entrance time (sec)\",\n",
    "                      \"Lick Onset Delay\",\"Forward Running Speed\",\"Successive Entrance Score\"]\n",
    "\n",
    "#     PerfParamToPlot =[\"Maximum Position\"]\n",
    "    \n",
    "    #put the desired profile for the sessions to be included\n",
    "#     profile={'Type':'Good',\n",
    "#          'rewardType':'Progressive',\n",
    "#          'initialSpeed':'10',\n",
    "#          'Speed':'10',\n",
    "#          'Tag':'Control'\n",
    "#          }\n",
    "    profile={'Type':'Good'}#AnimalProfile\n",
    "    # this is where you define a list of functions you want to run on your data (usually, don't touch!)\n",
    "    plotFunctionList=[plot_session_behavior]\n",
    "\n",
    "    #================================================\n",
    "    print(\"animals that will be analyzed: %s\"%animalList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Loops through animals and sessions and functions\n",
    "\n",
    "### Using 2 Parallel Processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    animals=animalList.copy()\n",
    "\n",
    "    class animalThread (Process):\n",
    "        def __init__(self,**kwargs):\n",
    "            Process.__init__(self)\n",
    "            assert 'animal' in kwargs.keys(), \"bad input\"\n",
    "\n",
    "            for key in kwargs:\n",
    "                self.__dict__[key]=kwargs[key]\n",
    "\n",
    "        def run(self):\n",
    "            print(\"Animal: %s\"%self.animal)\n",
    "            if updateTagFiles:\n",
    "                try:\n",
    "                    update_tag_file(self.root,self.animal)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            if replaceHtml:\n",
    "                for plotFunction in plotFunctionList:\n",
    "                    name = str(plotFunction.__name__)\n",
    "                    #html for the animal\n",
    "                    generalName = \"all_\" + name\n",
    "                    AnalysisFolder = os.path.join(self.root, self.animal, \"Analysis\")\n",
    "                    generalPath = os.path.join(AnalysisFolder, generalName+\".html\")\n",
    "                    if os.path.exists(generalPath):\n",
    "                        os.remove(generalPath)\n",
    "\n",
    "            plot_learningCurves(root=self.root,animal=self.animal,PerfParamToPlot=PerfParamToPlot,profile=self.profile,\n",
    "                                stop_date='',parameter=param,redoPreprocess=redoPreprocess,\n",
    "                                redoStat=redoStat,override=override,plot=plot,PrintWarning=PrintWarning)\n",
    "            plt.close('all')\n",
    "\n",
    "\n",
    "    threads = []\n",
    "    for animal in animals:\n",
    "        thread=animalThread(root=root,animal=animal,PerfParamToPlot=PerfParamToPlot,profile=profile,\n",
    "                            stop_date='',parameter=param,redoPreprocess=redoPreprocess,\n",
    "                            redoStat=redoStat,override=override,plot=plot,PrintWarning=PrintWarning)\n",
    "        threads.append(thread)\n",
    "    \n",
    "    #Running the Processes\n",
    "    N=2\n",
    "    threads=iter(threads)  \n",
    "    try:\n",
    "        while 1:\n",
    "            a=[]\n",
    "            for i in range(N):\n",
    "                a.append(next(threads))\n",
    "                a[-1].start()\n",
    "\n",
    "            for thread in a:\n",
    "                thread.join()\n",
    "    except StopIteration:\n",
    "        for thread in a:\n",
    "            thread.join()\n",
    "    \n",
    "    print (\"Exiting Main Process\")\n",
    "    \n",
    "    clear_output()\n",
    "    plt.close('all')\n",
    "    gc.collect() #Running the default Python Garbage Collector\n",
    "    update_animal_table_file(root,days_to_check=5)\n",
    "    shutil.copy(src=os.path.join(root,'ALLRAT_Analysis','RatTable.html'),\n",
    "                dst=os.path.join('/NAS02','ALLRAT_Analysis','RatTable.html'));\n",
    "    for animal in animalList:\n",
    "        imagePath=os.path.join(root,animal,'Analysis','LearningCurves.png')\n",
    "        try:\n",
    "            logging.info(animal)\n",
    "            display(Image(filename=imagePath))\n",
    "        except Exception as e:\n",
    "            print(animal,repr(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    #---------------------------iterate over animal-------------------------------------\n",
    "#     OUT={}\n",
    "    for animal in animalList:\n",
    "        print(\"Animal: %s\"%animal)\n",
    "        print(\"**********\")\n",
    "        if updateTagFiles:\n",
    "            try:\n",
    "                update_tag_file(root,animal)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        if replaceHtml:\n",
    "            for plotFunction in plotFunctionList:\n",
    "                name = str(plotFunction.__name__)\n",
    "                #html for the animal\n",
    "                generalName = \"all_\" + name\n",
    "                AnalysisFolder = os.path.join(root, animal, \"Analysis\")\n",
    "                generalPath = os.path.join(AnalysisFolder, generalName+\".html\")\n",
    "                if os.path.exists(generalPath):\n",
    "                    os.remove(generalPath)\n",
    "\n",
    "        plot_learningCurves(root,animal,PerfParamToPlot=PerfParamToPlot,profile=profile,\n",
    "                            stop_date='',parameter=param,redoPreprocess=redoPreprocess,\n",
    "                            redoStat=redoStat,override=override,plot=plot,PrintWarning=PrintWarning)\n",
    "        print(\"Done!\")\n",
    "        plt.close('all')\n",
    "             \n",
    "    clear_output()\n",
    "    gc.collect() #Running the default Python Garbage Collector\n",
    "    plt.close('all')\n",
    "    update_animal_table_file(root,days_to_check=5)\n",
    "    update_animal_table_file(root='/NAS02',days_to_check=5)\n",
    "    for animal in animalList:\n",
    "        imagePath=os.path.join(root,animal,'Analysis','LearningCurves.png')\n",
    "        try:\n",
    "            display(Image(filename=imagePath))\n",
    "        except Exception as e:\n",
    "            print(animal,repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### N Thread computing of any animal list (Do not use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func(animal):\n",
    "    print(\"Animal: %s\"%animal)\n",
    "    if updateTagFiles:\n",
    "        try:\n",
    "            update_tag_file(root,animal)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    if replaceHtml:\n",
    "        for plotFunction in plotFunctionList:\n",
    "            name = str(plotFunction.__name__)\n",
    "            #html for the animal\n",
    "            generalName = \"all_\" + name\n",
    "            AnalysisFolder = os.path.join(root, animal, \"Analysis\")\n",
    "            generalPath = os.path.join(AnalysisFolder, generalName+\".html\")\n",
    "            if os.path.exists(generalPath):\n",
    "                os.remove(generalPath)\n",
    "\n",
    "    plot_learningCurves(root,animal,PerfParamToPlot=PerfParamToPlot,profile=profile,\n",
    "                        stop_date='',parameter=param,redoPreprocess=redoPreprocess,\n",
    "                        redoStat=redoStat,override=override,plot=plot,PrintWarning=PrintWarning)\n",
    "\n",
    "if \"__file__\" not in dir():\n",
    "    N=3;#os.cpu_count()//os.cpu_count()\n",
    "    with Pool(processes=N) as pool:\n",
    "        pool.map(func,animalList)\n",
    "#         for animal in animalList:\n",
    "#             pool.apply_async(func, (animal,))\n",
    "\n",
    "    gc.collect()\n",
    "    clear_output()\n",
    "    plt.close('all')\n",
    "    print(\"closing the POOL\")\n",
    "    #update_animal_table_file(root,days_to_check=5)\n",
    "    for animal in animalList:\n",
    "        imagePath=os.path.join(root,animal,'Analysis','LearningCurves.png')\n",
    "        try:\n",
    "            display(Image(filename=imagePath))\n",
    "        except Exception as e:\n",
    "            print(animal,repr(e))   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    update_animal_table_file(root='/NAS02',days_to_check=5)\n",
    "    update_animal_table_file(root,days_to_check=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
