{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from platform import system as OS\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import math\n",
    "import datetime\n",
    "from copy import deepcopy\n",
    "from IPython.display import clear_output, display, HTML, Image\n",
    "import matplotlib.cm as cm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys, time\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from matplotlib import mlab\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.animation as animation\n",
    "from pylab import *\n",
    "import matplotlib.backends.backend_pdf\n",
    "\n",
    "\n",
    "root='/data'\n",
    "%run Animal_Tags.ipynb\n",
    "%run BatchRatBehavior.ipynb\n",
    "%run plotRat_documentation_3_KinematicsInvestigation.ipynb\n",
    "%run plotRat_documentation_1_GeneralBehavior.ipynb\n",
    "%run loadRat_documentation.ipynb\n",
    "# %run RunBatchRat_3_CompareGroups.ipynb\n",
    "# %run UtilityTools.ipynb\n",
    "\n",
    "defaultParam={\n",
    "    \"binSize\":0.25,\n",
    "    \"trialOffset\":20., #max end of trial, in seconds (position will be cutted)\n",
    "    \"sigmaSmoothPosition\":0.1,  #smooth the position\n",
    "    #\"sigmaSmoothPosition\":0.33 for pavel dataType\n",
    "    \"sigmaSmoothSpeed\":0.3, #smooth the speed\n",
    "    \"positionDiffRange\": [2.,5.], #min and max differences allowed between two consecutive positions\n",
    "                                  #min to correct start, max to correct jumps\n",
    "    \"pawFrequencyRange\":[2.,10.],\n",
    "    \"startAnalysisParams\":[10,0.2,0.5],\n",
    "    \"cameraToTreadmillDelay\":2., #seconds, usual time between camera start and treadmill start\n",
    "    \"nbJumpMax\" : 100., #if jumps>nbJumpMax, trial is badly tracked\n",
    "    \n",
    "    \n",
    "    #parameter to detect end of trial (first position minima)\n",
    "    \"endTrial_backPos\":55,  # minima is after the animal went once to the back (after first time position>backPos)\n",
    "    \"endTrial_frontPos\":30, # minima's position is in front of treadmill (position[end]<frontPos)\n",
    "    \"endTrial_minTimeSec\":4, # minima is after minTimeSec seconds (time[end]>minTimeSec)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# general modeling of forward speed by lesion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    profile1={'Type':'Good',\n",
    "             'rewardType':'Progressive',\n",
    "             'initialSpeed':['0','10'],\n",
    "             'Speed':'10',\n",
    "             'Tag':['Control','Control-AfterBreak','Control-Late-NoTimeout-BackToTimeout',\n",
    "                    'Control-NoTimeout-Control']\n",
    "             }\n",
    "    profile2={'Type':'Good',\n",
    "             'rewardType':'Progressive',\n",
    "             'initialSpeed':['0','10'],\n",
    "             'Speed':'10',\n",
    "             'Tag':['Late-Lesion_DMS','Late-Lesion_DLS','Late-Lesion_DS']\n",
    "             }\n",
    "    \n",
    "    _,sessionDic=event_detect(root,profile1,profile2)\n",
    "    \n",
    "    PerfParamToPlot=['Forward Running Speed']\n",
    "    \n",
    "    profile={'Type':'Good'}#AnimalProfile\n",
    "    # this is where you define a list of functions you want to run on your data (usually, don't touch!)\n",
    "    plotFunctionList=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:AssertionError('No Excel files/NAS02/Rat251/Rat251*.xls*')\n",
      "WARNING:root:AssertionError('No Excel files/NAS02/Rat308/Rat308*.xls*')\n",
      "WARNING:root:AssertionError('No Excel files/NAS02/Rat138/Rat138*.xls*')\n",
      "WARNING:root:AssertionError('No Excel files/NAS02/Rat299/Rat299*.xls*')\n",
      "WARNING:root:AssertionError('No Excel files/NAS02/Rat252/Rat252*.xls*')\n",
      "WARNING:root:AssertionError('No Excel files/NAS02/Rat255/Rat255*.xls*')\n",
      "WARNING:root:AssertionError('No Excel files/NAS02/Rat260/Rat260*.xls*')\n",
      "WARNING:root:AssertionError('No Excel files/NAS02/Rat305/Rat305*.xls*')\n",
      "WARNING:root:AssertionError('No Excel files/NAS02/Rat256/Rat256*.xls*')\n"
     ]
    }
   ],
   "source": [
    "if \"__file__\" not in dir():\n",
    "    animals, behav, lesionData= late_lesion_data(root,PerfParamToPlot,profile1,profile2,\n",
    "                                                 method=['lesion_size1','lesion_size2',\n",
    "                                                         'lesion_location1','lesion_location2',\n",
    "                                                        'lesion_depth1','lesion_depth2'],\n",
    "                                                 Ndays=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building Regressor Matrix, X from lesionData\n",
    "\n",
    "X=np.ones( (len(animals), len(lesionData.keys())) )*np.nan\n",
    "for i,feature in enumerate(lesionData):\n",
    "    print(feature)\n",
    "    X[:,i]=lesionData[feature]\n",
    "y=np.array(behav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The actual model\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_= poly.fit_transform(X)\n",
    "\n",
    "reg = LinearRegression().fit(X_[:10,:], y[:10])\n",
    "reg.names=poly.get_feature_names(list(lesionData.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for  i,co in enumerate(reg.coef_):\n",
    "#     if abs(co)>3000:\n",
    "        print(co,'\\t',reg.names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.Lasso(alpha=0.2)\n",
    "reg.fit(X_,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=reg.predict(X_)\n",
    "plt.plot(pred,y,'.')\n",
    "plt.xlim([-30,10])\n",
    "plt.ylim([-30,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.score(X_,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimentionality reduction methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lesion_size1\n",
      "lesion_size2\n",
      "lesion_location1\n",
      "lesion_location2\n",
      "lesion_depth1\n",
      "lesion_depth2\n"
     ]
    }
   ],
   "source": [
    "#Building Regressor Matrix, X from lesionData\n",
    "\n",
    "X=np.ones( (len(animals), len(lesionData.keys())) )*np.nan\n",
    "for i,feature in enumerate(lesionData):\n",
    "    print(feature)\n",
    "    X[:,i]=lesionData[feature]\n",
    "y=np.array(behav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76344426, 0.12402174, 0.05945318, 0.04514422, 0.00492872,\n",
       "       0.00300787])"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "factor analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import FactorAnalysis\n",
    "fa = FactorAnalysis(n_components=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FactorAnalysis(copy=True, iterated_power=3, max_iter=1000, n_components=6,\n",
       "        noise_variance_init=None, random_state=0, svd_method='randomized',\n",
       "        tol=0.01)"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09923958  0.07763313  0.04430704  0.04666073 -0.05518548  0.05982616]\n",
      " [ 0.13151239  0.12867563 -0.02631025 -0.02952465 -0.00034881  0.00269595]\n",
      " [-0.         -0.         -0.         -0.         -0.          0.        ]\n",
      " [ 0.         -0.          0.         -0.         -0.         -0.        ]\n",
      " [-0.          0.         -0.          0.         -0.         -0.        ]\n",
      " [-0.          0.          0.         -0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(fa.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 behavioral params corealated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.backends.backend_pdf\n",
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"output.pdf\")\n",
    "for fig in xrange(1, figure().number):\n",
    "    pdf.savefig( fig )\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnimalProfile={'Type':'Good',\n",
    "#          'option': ['not used'],\n",
    "     'rewardType':'Progressive',\n",
    "     'initialSpeed':['10','0'],\n",
    "     'Speed':'10',\n",
    "     'Tag':['Control']#,'Early-Lesion_DS','Early-Lesion_DMS','Early-Lesion_DLS',\n",
    "#            'Late-Lesion_DMS','Late-Lesion_DLS','Late-Lesion_DS']\n",
    "              }\n",
    "PerfParam=['standard deviation of entrance time',\"Forward Running Speed\"]#'Entrance Time MSE',\n",
    "AnimalList=batch_get_animal_list(root,AnimalProfile)\n",
    "Sessions=batch_get_session_list(root,AnimalList,profile=AnimalProfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = matplotlib.backends.backend_pdf.PdfPages(\"/home/david/output.pdf\")\n",
    "for animal in AnimalList:\n",
    "    Sessions=batch_get_session_list(root,[animal],profile=AnimalProfile)\n",
    "    b=[]\n",
    "    a=[]\n",
    "    for session in Sessions['Sessions']:\n",
    "        data=Data(root,session[:6],session,{},redoPreprocess=False)\n",
    "\n",
    "        dic=compute_or_read_stats(data, PerfParamToPlot=PerfParam, \n",
    "                                  saveAsPickle=False, redo=False)\n",
    "        if isinstance(dic[PerfParam[0]],(int,float)) and isinstance(dic[PerfParam[0]],(int,float)):\n",
    "            a.append(dic[PerfParam[0]])\n",
    "            b.append(dic[PerfParam[1]])\n",
    "\n",
    "    plt.scatter(a,b,c='k')\n",
    "#     plt.xlim(0,75)\n",
    "    plt.title(animal)\n",
    "    plt.xlabel(PerfParam[0])\n",
    "    plt.ylabel(PerfParam[1])\n",
    "    pdf.savefig( plt.gcf() )\n",
    "    plt.close()\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trimmed mean function\n",
    "averaging after removing outliers (-+3 SDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trimmed_mean(x):\n",
    "    if len(x)<50:\n",
    "        return np.nanmean(x)\n",
    "    SD=np.nanstd(x)\n",
    "    MEAN=np.nanmean(x)\n",
    "    out=scipy.stats.tmean(x, limits=(MEAN-3*SD,MEAN+3*SD), inclusive=(False, False), axis=None)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initial position's role in entrance time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "median entrance time of trials in different initial position bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animalList=batch_get_animal_list(root,AnimalProfile)\n",
    "rawPos=[]\n",
    "ET=[]\n",
    "countN=0\n",
    "countP=0\n",
    "for animal in  animalList:\n",
    "    sessionDict=batch_get_session_list(root,[animal],profile=AnimalProfile)\n",
    "    if SESSION_LIMIT >0:\n",
    "        tmp=sessionDict['Sessions'][:SESSION_LIMIT]\n",
    "    else:\n",
    "        tmp=sessionDict['Sessions'][SESSION_LIMIT:]\n",
    "    \n",
    "    for session in tmp:\n",
    "        picklePath=os.path.join(root,animal,'Experiments',session,'Analysis','rawbehaviordata.p')\n",
    "        with open(picklePath,'rb') as f:\n",
    "            data=pickle.load(f)\n",
    "        try:\n",
    "            rawPos0=[data['rawPosition'][i][0] for i in data['rawPosition']]\n",
    "            ET0=data['entranceTime']\n",
    "        except:pass\n",
    "        if len(ET0)==len(rawPos0):\n",
    "            rawPos.extend(rawPos0)\n",
    "            ET.extend(ET0)\n",
    "            countP+=len(ET0)\n",
    "        else:\n",
    "            countN+=1\n",
    "\n",
    "print('removed sessions:',countN)\n",
    "print('good trials:',countP)\n",
    "ET=np.array(ET)\n",
    "rawPos=np.array(rawPos)\n",
    "stat,bins,_=scipy.stats.binned_statistic(rawPos,ET, statistic='median')\n",
    "plt.bar(bins[0:-1]+5,stat,width=bins[1]-bins[0],edgeColor='k')\n",
    "plt.ylim(3,8)\n",
    "plt.xlabel('initial position')\n",
    "plt.ylabel('ET')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(correct trial | initial position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnimalProfile={'Type':'Good',\n",
    "     'rewardType':'Progressive',\n",
    "     'initialSpeed':'10',\n",
    "     'Speed':['10'],\n",
    "     'Tag':'Control'\n",
    "              }\n",
    "SESSION_LIMIT=-5\n",
    "GoalTime=7\n",
    "MaxTrialTime=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animalList=batch_get_animal_list(root,AnimalProfile)\n",
    "\n",
    "bins=[10,20,30,40,50,60,70,80]\n",
    "pos=[]\n",
    "et=[]\n",
    "for animal in  animalList:\n",
    "    sessionDict=batch_get_session_list(root,[animal],profile=AnimalProfile)\n",
    "    if SESSION_LIMIT >0:\n",
    "        tmp=sorted(sessionDict['Sessions'])[:SESSION_LIMIT]\n",
    "    else:\n",
    "        tmp=sorted(sessionDict['Sessions'])[SESSION_LIMIT:]\n",
    "        \n",
    "    for session in tmp:\n",
    "        picklePath=os.path.join(root,animal,'Experiments',session,'Analysis','preprocesseddata_binsize250ms_.p')\n",
    "        with open(picklePath,'rb') as f:\n",
    "            data=pickle.load(f)\n",
    "        try:\n",
    "            rawPos0=np.array([data['position'][i][0] for i in data['position']])\n",
    "            ET0=np.array(data['entranceTime'])\n",
    "        except:\n",
    "            ET0=[]\n",
    "            rawPos0=[0,0]\n",
    "        if len(ET0)==len(rawPos0):\n",
    "            pos.extend(rawPos0.tolist())\n",
    "            et.extend(ET0.tolist())\n",
    "        else:\n",
    "            countN+=1\n",
    "def p_correct(a):\n",
    "    return sum(np.logical_and(a >= GoalTime, a < MaxTrialTime))/len(a)\n",
    "print('removed sessions:',countN)\n",
    "print('session limit:',SESSION_LIMIT)\n",
    "et=np.array(et)\n",
    "pos=np.array(pos)\n",
    "stat,bins,_=scipy.stats.binned_statisticv(pos,et, statistic=p_correct,bins=bins)\n",
    "plt.bar(bins[0:-1]+5,stat,width=bins[1]-bins[0],edgeColor='k')\n",
    "plt.title('P(correct trials | initial position)')\n",
    "plt.xlabel('initial position')\n",
    "plt.ylabel('probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probablity distribution of correct trials along the length of the treadmill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnimalProfile={'Type':'Good',\n",
    "     'rewardType':'Progressive',\n",
    "     'initialSpeed':'10',\n",
    "     'Speed':['10'],\n",
    "     'Tag':'Control'\n",
    "              }\n",
    "SESSION_LIMIT=-55\n",
    "GoalTime=7\n",
    "MaxTrialTime=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animalList=batch_get_animal_list(root,AnimalProfile)\n",
    "animalList=['Rat084']\n",
    "rawPos=[]\n",
    "countN=0\n",
    "countP=0\n",
    "for animal in  animalList:\n",
    "    sessionDict=batch_get_session_list(root,[animal],profile=AnimalProfile)\n",
    "    if SESSION_LIMIT >0:\n",
    "        tmp=sorted(sessionDict['Sessions'])[:SESSION_LIMIT]\n",
    "    else:\n",
    "        tmp=sorted(sessionDict['Sessions'])[SESSION_LIMIT:]\n",
    "    for session in tmp:\n",
    "        picklePath=os.path.join(root,animal,'Experiments',session,'Analysis','preprocesseddata_binsize250ms_.p')\n",
    "        with open(picklePath,'rb') as f:\n",
    "            data=pickle.load(f)\n",
    "        try:\n",
    "            rawPos0=np.array([data['position'][i][0] for i in data['position']])\n",
    "            ET0=np.array(data['entranceTime'])\n",
    "        except:\n",
    "            ET0=[]\n",
    "            rawPos0=[0,0]\n",
    "        if len(ET0)==len(rawPos0):\n",
    "            rawPos0=rawPos0[np.logical_and(ET0 >= GoalTime, ET0 < MaxTrialTime)]\n",
    "            rawPos.extend(rawPos0)\n",
    "            countP+=len(rawPos0)\n",
    "        else:\n",
    "            countN+=1\n",
    "\n",
    "print('removed sessions:',countN)\n",
    "print('good trials:',countP)\n",
    "print('session limit:',SESSION_LIMIT)\n",
    "rawPos=np.array(rawPos)\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.hist(rawPos,normed=True,edgecolor='k',color='g')\n",
    "plt.xlabel('Initial Position (cm)')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('P(initial position|correct trial)')\n",
    "plt.ylim(0,.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### effect of initial position on the trajectory\n",
    "\n",
    "also number of in-the-back-trials seem to decline with learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def position_based_trajectory(root,animalList,TRD_RANGE,SESSION_LIMIT,MAX_L):\n",
    "    traj=[]\n",
    "    Ntrial=0\n",
    "    for animal in  animalList:\n",
    "        sessionDict=batch_get_session_list(root,[animal],profile=AnimalProfile)\n",
    "        if SESSION_LIMIT >0:\n",
    "            tmp=sorted(sessionDict['Sessions'])[:SESSION_LIMIT]\n",
    "        else:\n",
    "            tmp=sorted(sessionDict['Sessions'])[SESSION_LIMIT:]\n",
    "\n",
    "        for session in tmp:\n",
    "            picklePath=os.path.join(root,animal,'Experiments',session,'Analysis','preprocesseddata_binsize250ms_.p')\n",
    "            try:\n",
    "                with open(picklePath,'rb') as f:\n",
    "                    data=pickle.load(f)\n",
    "                goodTrials=[trial for trial in data['position'] if data['position'][trial][0] > TRD_RANGE[0] and data['position'][trial][0] < TRD_RANGE[1]]\n",
    "                Ntrial+=len(goodTrials)\n",
    "            except:\n",
    "                goodTrials=[]\n",
    "\n",
    "            traj.extend([data['position'][i] for i in goodTrials])\n",
    "\n",
    "    Traj=np.ones((MAX_L,len(traj)))*np.nan\n",
    "\n",
    "    for i,pos in enumerate(traj):\n",
    "        Traj[:min(len(pos),MAX_L),i]=pos[:min(len(pos),MAX_L)]\n",
    "    print(Ntrial)    \n",
    "    return Traj,Ntrial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "AnimalProfile={'Type':'Good',\n",
    "     'rewardType':'Progressive',\n",
    "     'initialSpeed':['10'],\n",
    "     'Speed':['10'],\n",
    "     'Tag':'Control-NoTimeout'\n",
    "              }\n",
    "\n",
    "animalList=batch_get_animal_list(root,AnimalProfile)\n",
    "\n",
    "SESSION_LIMIT=5\n",
    "TRD_RANGE   = [[55,100],[30,55],[0,25]]\n",
    "MAX_L        =500\n",
    "plt.figure(figsize=[15,5])\n",
    "for i in range(len(TRD_RANGE)):\n",
    "    plt.subplot(1,len(TRD_RANGE),i+1)\n",
    "    TrajNaive,_=position_based_trajectory(root,animalList,TRD_RANGE[i],SESSION_LIMIT,MAX_L)\n",
    "    SESSION_LIMIT=-SESSION_LIMIT\n",
    "    TrajTrained,_=position_based_trajectory(root,animalList,TRD_RANGE[i],SESSION_LIMIT,MAX_L)\n",
    "    SESSION_LIMIT=-SESSION_LIMIT\n",
    "    \n",
    "    plt.plot(np.arange(MAX_L)/25,np.nanmedian(TrajNaive,axis=1),'b',label='Naive')\n",
    "    plt.fill_between(np.arange(MAX_L)/25,np.nanpercentile(TrajNaive, 25, axis=1),np.nanpercentile(TrajNaive, 75, axis=1),color='blue',alpha=0.25)\n",
    "    plt.plot(np.arange(MAX_L)/25,np.nanmedian(TrajTrained,axis=1),'r',label='Trained')\n",
    "    plt.fill_between(np.arange(MAX_L)/25,np.nanpercentile(TrajTrained, 25, axis=1),np.nanpercentile(TrajTrained, 75, axis=1),color='red',alpha=0.25)\n",
    "\n",
    "    plt.xlabel('time(s)')\n",
    "    plt.ylabel('position (cm)')\n",
    "    plt.xlim([0,15])\n",
    "    plt.ylim([0,90])\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### percentage of fast correct trials in trained sessions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_correct_given_speed(root,AnimalProfile,SESSION_LIMIT,SPEED_RANGE):\n",
    "    animalList=batch_get_animal_list(root,AnimalProfile)\n",
    "    N=0\n",
    "    goodN=0\n",
    "    countN=0\n",
    "    countP=0\n",
    "    for animal in  animalList:\n",
    "        sessionDict=batch_get_session_list(root,[animal],profile=AnimalProfile)\n",
    "        if SESSION_LIMIT >0:\n",
    "            tmp=sorted(sessionDict['Sessions'])[:SESSION_LIMIT]\n",
    "        else:\n",
    "            tmp=sorted(sessionDict['Sessions'])[SESSION_LIMIT:]\n",
    "        for session in tmp:\n",
    "            picklePath=os.path.join(root,animal,'Experiments',session,'Analysis','preprocesseddata_binsize250ms_.p')\n",
    "            filePath=os.path.join(root,animal,'Experiments',session,session)\n",
    "            with open(picklePath,'rb') as f:\n",
    "                data=pickle.load(f)\n",
    "            try:\n",
    "                spd0=read_in_file(filePath,paramName=' ',extension='.variablespeed',valueType=float)\n",
    "                ET0=np.array(data['entranceTime'])\n",
    "            except:\n",
    "                spd0=[]\n",
    "                ET0=[0,0]\n",
    "            if len(ET0)==len(spd0):\n",
    "                goodTrial=ET0[np.logical_and(spd0 >= SPEED_RANGE[0], spd0 <SPEED_RANGE[-1])]\n",
    "                N+=np.sum(ET0>=7)\n",
    "                goodN+=np.sum(goodTrial>=7)\n",
    "                countP+=1\n",
    "            else:\n",
    "                countN+=1\n",
    "    print('+trial:',countP)\n",
    "    print('-trial:',countN)\n",
    "    return goodN,N    \n",
    "\n",
    "\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "AnimalProfile={'Type':'Good',\n",
    "     'rewardType':'Progressive',\n",
    "     #'initialSpeed':['var'],\n",
    "     'Speed':['var'],\n",
    "     'Tag':'Early-Lesion_DMS-Early-var'\n",
    "              }\n",
    "\n",
    "animalList=batch_get_animal_list(root,AnimalProfile)\n",
    "SESSION_LIMIT=5\n",
    "SPEED_RANGE        =[[5,15],[20,30]]\n",
    "plt.figure(figsize=[15,5])\n",
    "goodN0S,N0=P_correct_given_speed(root,AnimalProfile,SESSION_LIMIT,SPEED_RANGE[0])\n",
    "goodN0F,N0=P_correct_given_speed(root,AnimalProfile,SESSION_LIMIT,SPEED_RANGE[1])\n",
    "SESSION_LIMIT=-SESSION_LIMIT\n",
    "goodN1S,N1=P_correct_given_speed(root,AnimalProfile,SESSION_LIMIT,SPEED_RANGE[0])\n",
    "goodN1F,N1=P_correct_given_speed(root,AnimalProfile,SESSION_LIMIT,SPEED_RANGE[1])\n",
    "SESSION_LIMIT=-SESSION_LIMIT\n",
    "\n",
    "plt.bar([0,1],[goodN0S/N0,goodN0F/N0],color='b',label='Naive')\n",
    "plt.bar([3,4],[goodN1S/N1,goodN1F/N1],color='r',label='Trained')\n",
    "plt.xticks([0,1,3,4],['slow','fast','slow','fast'])\n",
    "plt.legend();\n",
    "plt.title('P(correct trials)');\n",
    "plt.ylabel('Probablity of correct trial');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trajectory evolution for bad/good trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_evolution(root,animalList,SESSION_LIMIT,MAX_L):\n",
    "    goodTraj=[]\n",
    "    badTraj=[]\n",
    "    Ntrial=0\n",
    "    for animal in  animalList:\n",
    "        sessionDict=batch_get_session_list(root,[animal],profile=AnimalProfile)\n",
    "        if SESSION_LIMIT >0:\n",
    "            tmp=sorted(sessionDict['Sessions'])[:SESSION_LIMIT]\n",
    "        else:\n",
    "            tmp=sorted(sessionDict['Sessions'])[SESSION_LIMIT:]\n",
    "\n",
    "        for session in tmp:\n",
    "            picklePath=os.path.join(root,animal,'Experiments',session,'Analysis','preprocesseddata_binsize250ms_.p')\n",
    "            try:\n",
    "                with open(picklePath,'rb') as f:\n",
    "                    data=pickle.load(f)\n",
    "                ET0=np.array(data['entranceTime'])\n",
    "                goodTrials=np.nonzero(np.logical_and(ET0>=7, ET0<15))[0].tolist()\n",
    "                badTrials =np.nonzero(ET0< 7)[0].tolist()\n",
    "                Ntrial+=len(goodTrials)\n",
    "            except Exception as e:\n",
    "                print(repr(e))\n",
    "                goodTrials=[]\n",
    "                badTrials=[]\n",
    "\n",
    "            goodTraj.extend([data['position'][i] for i in goodTrials if i+1 in data['realTrials']])\n",
    "            badTraj.extend ([data['position'][i] for i in badTrials  if i+1 in data['realTrials']])\n",
    "\n",
    "    GoodTraj=np.ones((MAX_L,len(goodTraj)))*np.nan\n",
    "    BadTraj =np.ones((MAX_L,len(badTraj )))*np.nan\n",
    "\n",
    "    for i,pos in enumerate(goodTraj):\n",
    "        GoodTraj[:min(len(pos),MAX_L),i]=pos[:min(len(pos),MAX_L)]\n",
    "    for i,pos in enumerate(badTraj):\n",
    "        BadTraj[:min(len(pos),MAX_L),i]=pos[:min(len(pos),MAX_L)]\n",
    "\n",
    "    print(Ntrial)    \n",
    "    return GoodTraj,BadTraj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnimalProfile={'Type':'Good',\n",
    "     'rewardType':'Progressive',\n",
    "     'initialSpeed':['10'],\n",
    "     'Speed':['10'],\n",
    "     'Tag':'Control'\n",
    "              }\n",
    "\n",
    "animalList=batch_get_animal_list(root,AnimalProfile)\n",
    "\n",
    "SESSION_LIMIT=5\n",
    "MAX_L        =500\n",
    "plt.figure(figsize=(15,5))\n",
    "goodNaive,badNaive=trajectory_evolution(root,animalList,SESSION_LIMIT,MAX_L)\n",
    "SESSION_LIMIT=-SESSION_LIMIT\n",
    "goodTrained,badTrained=trajectory_evolution(root,animalList,SESSION_LIMIT,MAX_L)\n",
    "SESSION_LIMIT=-SESSION_LIMIT\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(np.arange(MAX_L)/25,np.nanmedian(goodNaive,axis=1),'b',label='good trial')\n",
    "plt.fill_between(np.arange(MAX_L)/25,np.nanpercentile(goodNaive, 25, axis=1),np.nanpercentile(goodNaive, 75, axis=1),color='blue',alpha=0.25)\n",
    "plt.plot(np.arange(MAX_L)/25,np.nanmedian(badNaive,axis=1),'r',label='bad trial')\n",
    "plt.fill_between(np.arange(MAX_L)/25,np.nanpercentile(badNaive, 25, axis=1),np.nanpercentile(badNaive, 75, axis=1),color='red',alpha=0.25)\n",
    "plt.xlabel('time(s)')\n",
    "plt.ylabel('position (cm)')\n",
    "plt.xlim([0,15])\n",
    "plt.ylim([0,90])\n",
    "plt.title('Naive')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(np.arange(MAX_L)/25,np.nanmedian(goodTrained,axis=1),'b',label='good trial')\n",
    "plt.fill_between(np.arange(MAX_L)/25,np.nanpercentile(goodTrained, 25, axis=1),np.nanpercentile(goodTrained, 75, axis=1),color='blue',alpha=0.25)\n",
    "plt.plot(np.arange(MAX_L)/25,np.nanmedian(badTrained,axis=1),'r',label='bad trial')\n",
    "plt.fill_between(np.arange(MAX_L)/25,np.nanpercentile(badTrained, 25, axis=1),np.nanpercentile(badTrained, 75, axis=1),color='red',alpha=0.25)\n",
    "\n",
    "plt.xlabel('time(s)')\n",
    "plt.xlim([0,15])\n",
    "plt.ylim([0,90])\n",
    "plt.legend();\n",
    "plt.title('Trained');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Permutation Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class permtest_output:\n",
    "    def __init__(self,D0,shuffledD=None,p_val=None,band=None, pairwise_CI=None,sig_signal=None):\n",
    "        self.statistic=D0\n",
    "        self.shuffled_data=shuffledD\n",
    "        self.p_val=p_val\n",
    "        self.significant=sig_signal\n",
    "        self.boundary=band\n",
    "        self.pairwise_alpha=pairwise_CI\n",
    "        self.significant=sig_signal\n",
    "\n",
    "        \n",
    "def perm_statistic(x,y,Nx,Ny,sigma=0):\n",
    "    \n",
    "    if len(x) <2:\n",
    "        return (x/Nx)-(y/Ny)\n",
    "    \n",
    "    #the gaussian kernel\n",
    "    x_smooth=scipy.ndimage.filters.gaussian_filter1d(x, sigma=sigma, order=0, mode='constant', cval=0, truncate=4.0)\n",
    "    y_smooth=scipy.ndimage.filters.gaussian_filter1d(y, sigma=sigma, order=0, mode='constant', cval=0, truncate=4.0)\n",
    "    \n",
    "    return (x_smooth/Nx)-(y_smooth/Ny)\n",
    "    \n",
    "def permtest(x,y, iterN=1000,sigma=0.05):\n",
    "    \"\"\"\n",
    "    Permutation test as to whether x>y or not.\n",
    "    x,y:\n",
    "    represent the data. they could be eitherr one dimentional(several realizations)\n",
    "    or 2-D (several realizaions through out the time/space/... course)\n",
    "        EX: x.shape==(15,500) means 15 trials/samples over 500 time bins\n",
    "    \n",
    "    iterN:\n",
    "    number of iterations used to shuffle\n",
    "    \n",
    "    sigma:\n",
    "    the standard deviation of the gaussian kernel used for smoothing when there are multiple data points,\n",
    "    based on the Fujisawa 2008 paper, default value: 0.05\n",
    "    \"\"\"\n",
    "    \n",
    "    #input check\n",
    "    if x.ndim>2 or y.ndim>2:\n",
    "        raise ValueError('bad input dimentions')\n",
    "    elif x.ndim==1 or y.ndim==1:\n",
    "        x=np.reshape(x,(len(x),1))\n",
    "        y=np.reshape(y,(len(y),1))\n",
    "    \n",
    "    #computing the tset statistic\n",
    "    xTrial,yTrial=x.shape[0],y.shape[0]\n",
    "    \n",
    "    x_superimpos=np.nansum(x,axis=0)\n",
    "    y_superimpos=np.nansum(y,axis=0)\n",
    "    \n",
    "    D0=perm_statistic(x_superimpos,y_superimpos,x.shape[0],y.shape[0])\n",
    "    \n",
    "    # shuffling the data\n",
    "    Dshuffled=np.ones((iterN,len(x_superimpos)))*np.nan\n",
    "    for i in range(iterN):\n",
    "        tmpShuffle=np.concatenate((x,y),axis=0)\n",
    "        np.random.shuffle(tmpShuffle)  #works in-plcae\n",
    "        xNew,yNew=tmpShuffle[:xTrial,:],tmpShuffle[xTrial:,:]\n",
    "        \n",
    "        xNew_superimpos=np.nansum(xNew,axis=0)\n",
    "        yNew_superimpos=np.nansum(yNew,axis=0)\n",
    "        \n",
    "        Dshuffled[i,:]=perm_statistic(xNew_superimpos,yNew_superimpos,xNew.shape[0],yNew.shape[0],sigma)\n",
    "    \n",
    "    if len(D0)<2:  #single point comparison\n",
    "        p_val0=np.sum(Dshuffled>=D0,axis=0)/(iterN+1)\n",
    "        return permtest_output(D0=D0,p_val=p_val0,shuffledD=Dshuffled,sig_signal=bool(p_val0<=0.05))\n",
    "    \n",
    "    #global bands\n",
    "    alpha=100\n",
    "    CI=5  #global confidance interval\n",
    "    pairwise_high_band=np.percentile(a=Dshuffled,q=100-CI,axis=0)\n",
    "    \n",
    "    while alpha>=5:\n",
    "        high_band=np.percentile(a=Dshuffled,q=100-CI,axis=0)\n",
    "        breaks=np.sum([np.sum(Dshuffled[i,:]>high_band)>1 for i in range(iterN)])\n",
    "        alpha=(breaks/iterN)*100\n",
    "        CI=0.95*CI\n",
    "        print(\"Global Confidence interval at \",CI,'\\nComputing again...\\n')\n",
    "    \n",
    "    #finding significant bins\n",
    "    global_sig=D0>high_band\n",
    "    pairwise_sig=D0>pairwise_high_band\n",
    "    sigIndex=np.where(global_sig)[0]\n",
    "    \n",
    "    for i in sigIndex:\n",
    "        if i==0 or i==len(global_sig):\n",
    "            continue\n",
    "        global_sig[np.min((np.where(pairwise_sig[:i])[0][-1],i)):np.max((np.where(pairwise_sig[i:])[0][-1],i))]=True\n",
    "    \n",
    "    return permtest_output(D0=D0,shuffledD=Dshuffled,sig_signal=global_sig,p_val=CI,band=high_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y=[52.0, 57.0, 65.0, 35.0, 72.0, 60.0, 68.0, 40.0, 32.0, 62.0, 60.0, 45.0, 60.0, 57.0]\n",
    "x=[72.0, 38.0, 72.0, 72.0, 72.0, 75.0, 72.0, 2.0, 18.0, 65.0]\n",
    "x=np.random.normal(loc=1.5, scale=1.0, size=(10,100))\n",
    "y=np.random.normal(loc=1.5, scale=1.0, size=(10,100))\n",
    "\n",
    "a=permtest(np.array(x),np.array(y), iterN=10000)\n",
    "a.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Duration/ Number of trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajectory_evolution(root,animalList,SESSION_LIMIT,MAX_L):\n",
    "    goodTraj=[]\n",
    "    badTraj=[]\n",
    "    Ntrial=0\n",
    "    for animal in  animalList:\n",
    "        sessionDict=batch_get_session_list(root,[animal],profile=AnimalProfile)\n",
    "        if SESSION_LIMIT >0:\n",
    "            tmp=sorted(sessionDict['Sessions'])[:SESSION_LIMIT]\n",
    "        else:\n",
    "            tmp=sorted(sessionDict['Sessions'])[SESSION_LIMIT:]\n",
    "\n",
    "        for session in tmp:\n",
    "            picklePath=os.path.join(root,animal,'Experiments',session,'Analysis','preprocesseddata_binsize250ms_.p')\n",
    "            try:\n",
    "                with open(picklePath,'rb') as f:\n",
    "                    data=pickle.load(f)\n",
    "                ET0=np.array(data['entranceTime'])\n",
    "                goodTrials=np.nonzero(np.logical_and(ET0>=7, ET0<15))[0].tolist()\n",
    "                badTrials =np.nonzero(ET0< 7)[0].tolist()\n",
    "                Ntrial+=len(goodTrials)\n",
    "            except Exception as e:\n",
    "                print(repr(e))\n",
    "                goodTrials=[]\n",
    "                badTrials=[]\n",
    "\n",
    "            goodTraj.extend([data['position'][i] for i in goodTrials if i+1 in data['realTrials']])\n",
    "            badTraj.extend ([data['position'][i] for i in badTrials  if i+1 in data['realTrials']])\n",
    "\n",
    "    GoodTraj=np.ones((MAX_L,len(goodTraj)))*np.nan\n",
    "    BadTraj =np.ones((MAX_L,len(badTraj )))*np.nan\n",
    "\n",
    "    for i,pos in enumerate(goodTraj):\n",
    "        GoodTraj[:min(len(pos),MAX_L),i]=pos[:min(len(pos),MAX_L)]\n",
    "    for i,pos in enumerate(badTraj):\n",
    "        BadTraj[:min(len(pos),MAX_L),i]=pos[:min(len(pos),MAX_L)]\n",
    "\n",
    "    print(Ntrial)    \n",
    "    return GoodTraj,BadTraj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnimalProfile={'Type':'Good',\n",
    "     'rewardType':'Progressive',\n",
    "     'initialSpeed':['10'],\n",
    "     'Speed':['10'],\n",
    "     'Tag':'Control'\n",
    "              }\n",
    "animalList=batch_get_animal_list(root,AnimalProfile)\n",
    "\n",
    "SESSION_LIMIT=5\n",
    "MAX_L        =500\n",
    "plt.figure(figsize=(15,5))\n",
    "goodNaive,badNaive=trajectory_evolution(root,animalList,SESSION_LIMIT,MAX_L)\n",
    "SESSION_LIMIT=-SESSION_LIMIT\n",
    "goodTrained,badTrained=trajectory_evolution(root,animalList,SESSION_LIMIT,MAX_L)\n",
    "SESSION_LIMIT=-SESSION_LIMIT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trajectory distance matrix instead of fucking correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(data,maxTreadmillLength=90):\n",
    "    '''\n",
    "    Compute the rmse of the position between trial start and trial stop (treadmill stop)\n",
    "    Returns the ...\n",
    "    '''\n",
    "    allTraj=get_positions_array_beginning(data)\n",
    "    NbTrial=allTraj.shape[0]\n",
    "    rmse=np.ones((NbTrial,NbTrial))*(-1)\n",
    "\n",
    "    for i in range(NbTrial):\n",
    "        for j in range(i+1,NbTrial):\n",
    "            maxL=min([np.sum(np.logical_not(np.isnan(allTraj[i,:]))),np.sum(np.logical_not(np.isnan(allTraj[j,:])))])\n",
    "            rmse[i,j]=np.sqrt(np.sum((allTraj[i,:maxL]-allTraj[j,:maxL])**2)/maxL)\n",
    "    out=np.triu(rmse,k=0)+np.triu(rmse,k=0).T #symetrical\n",
    "    return out/maxTreadmillLength\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=Data(root,'Rat077','Rat077_2016_10_07_10_15',defaultParam,redoPreprocess=False)\n",
    "a,b=plot_rmse(data);\n",
    "print(sum(b.flatten()<.25)/b.shape[0],a)\n",
    "plt.figure()\n",
    "plt.hist(b.flatten(),50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trajectories aligned at their peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positions_array_peaks_aligned(data,onlyGood=False,raw=False):\n",
    "    '''\n",
    "    Returns array of position, align on detected peak,\n",
    "    If one position is too short (detected end is before minTime), \n",
    "      the position is pad at the beginning and end with nan values\n",
    "    '''\n",
    "    if raw:\n",
    "        posDict=data.rawPosition\n",
    "    else:\n",
    "        posDict=data.position\n",
    "    #number of frames to keep \n",
    "    cs=data.cameraSamplingRate\n",
    "    size=int(scipy.stats.mode(data.maxTrialDuration)[0]*cs)+1 #int(abs(minTime*cs))\n",
    "    #put all positions in a 2D array\n",
    "    allTraj=np.ones([max(posDict.keys())+1,size*2])*np.nan  #matrix of trial position*time\n",
    "    for trial in posDict:\n",
    "        if onlyGood and (trial not in data.goodTrials):\n",
    "            continue\n",
    "        \n",
    "        #index where the trajectory begins and ends\n",
    "        endIndex  =data.stopFrame[trial] if isNone(data.indexEndTrial[trial]) else data.indexEndTrial[trial]\n",
    "        startIndex=data.startFrame[trial]\n",
    "        pos=posDict[trial][startIndex:endIndex]\n",
    "        peakIndex=np.argmax(pos)\n",
    "        indexOffset=size-peakIndex\n",
    "        allTraj[trial,indexOffset:indexOffset+len(pos)]=pos\n",
    "    return allTraj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rmse(data,alignedOnBegining=True,onlyGood=False,raw=False):\n",
    "    '''\n",
    "    Compute the rmse of the position between trial start and trial stop (treadmill stop)\n",
    "    plots and returns the RMSE matrix\n",
    "    '''\n",
    "    if alignedOnBegining:\n",
    "        allTraj=get_positions_array_beginning(data,onlyGood=onlyGood,raw=raw)\n",
    "    else:\n",
    "        allTraj=get_positions_array_peaks_aligned(data,onlyGood=onlyGood,raw=raw)\n",
    "    \n",
    "    NbTrial=allTraj.shape[0]\n",
    "    \n",
    "    if NbTrial<3:\n",
    "        title=\"Not enough trials\"\n",
    "        med=np.nan\n",
    "        return med\n",
    "\n",
    "    rmse=np.ones((NbTrial,NbTrial))*(-1)\n",
    "\n",
    "    for i in range(NbTrial):\n",
    "        rmse[i,i]=0\n",
    "        for j in range(i+1,NbTrial):\n",
    "            \n",
    "            a=allTraj[i,:]-allTraj[j,:]\n",
    "            rmse[i,j]=np.sqrt(np.nansum(a**2)/np.sum(np.logical_not(np.isnan(a))))\n",
    "    \n",
    "    RMSEmatrix=np.triu(rmse,k=0)+np.triu(rmse,k=0).T #symetrical\n",
    "    RMSEmatrix/=data.treadmillRange[1]\n",
    "    pp=plt.pcolor(RMSEmatrix,vmin=0,vmax=1,cmap=\"Reds\")\n",
    "    plt.colorbar(pp)\n",
    "    plt.xlim([0,RMSEmatrix.shape[0]])\n",
    "    plt.ylim([0,RMSEmatrix.shape[1]])\n",
    "    \n",
    "    #median of upper triangle of matrix\n",
    "    coef=RMSEmatrix[np.tril_indices(RMSEmatrix.shape[0],-1)]\n",
    "    #print(len(coef))\n",
    "    m=np.nanmean(coef)\n",
    "    maxSecond=allTraj.shape[1]/float(data.cameraSamplingRate)\n",
    "    #title of the plot\n",
    "    title=\"\"\n",
    "    if onlyGood:\n",
    "        title=\"Good Trials\"\n",
    "    else:\n",
    "        title=\"All Trials\"\n",
    "\n",
    "    title+=', trajectory m= %.2f'%m    \n",
    "    plt.title(title)\n",
    "\n",
    "    \n",
    "    return m,RMSEmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session='Rat164_2017_10_11_15_29'\n",
    "data=Data(root,session[:6],session,defaultParam,redoPreprocess=False)\n",
    "m,esme=plot_rmse(data,alignedOnBegining=False,onlyGood=False,raw=False)\n",
    "print(m)\n",
    "plt.figure()\n",
    "traj=get_positions_array_peaks_aligned(data,onlyGood=False,raw=False)\n",
    "plt.plot(traj.T);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trajectory Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session='Rat164_2017_10_11_15_29'\n",
    "# data=Data(root,session[:6],session,defaultParam,redoPreprocess=False)\n",
    "# allTraj=get_positions_array_beginning(data,False).T\n",
    "# plt.plot(np.arange((allTraj.shape[0]))/data.cameraSamplingRate,allTraj);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sessionDict=batch_get_session_list(root,[\"Rat166\"],profile={'Tag':'Control','Speed':'10','Type':'Good'})\n",
    "sessionList=sessionDict['Sessions']\n",
    "\n",
    "H=[]\n",
    "for i,session in enumerate(sessionList):\n",
    "    data=Data(root,session[:6],session,defaultParam,redoPreprocess=False)\n",
    "    fig=plt.figure()\n",
    "    ax=plt.subplot(111)\n",
    "    h=plot_trajectory_PDF(data,TimeRes=.5,PosRes=5,onlyGood=False)\n",
    "    plt.title(('day: '+str(i+1) + ', E='+ str(twoD_entropy(h))))\n",
    "    H.append(h)\n",
    "#     plt.close()\n",
    "#     plt.plot(H,'r-*')\n",
    "#     plt.ylim([7,10])\n",
    "#     plt.title(session[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y = np.linspace(0, 15, trajDis.shape[0])\n",
    "X = np.linspace(0, 90, trajDis.shape[1])\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(X, Y, trajDis/sum(trajDis.flatten()),cmap=cm.coolwarm,\n",
    "                       linewidth=0,antialiased=False)\n",
    "ax.set_xlabel('space')\n",
    "ax.set_ylabel('time')\n",
    "ax.invert_xaxis()\n",
    "ax.view_init(elev=20,azim=10)\n",
    "#fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoD_entropy(trajDist):\n",
    "    H=0\n",
    "    for i in range(trajDist.shape[0]):\n",
    "        for j in range(trajDist.shape[1]):\n",
    "            try:\n",
    "                H+=trajDist[i,j]*math.log(float(trajDist[i,j]),2)\n",
    "            except:\n",
    "                pass\n",
    "    H=-H\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpi = 100\n",
    "\n",
    "def ani_frame(data,trial):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "#     ax.set_aspect('equal')\n",
    "#     ax.get_xaxis().set_visible(False)\n",
    "#     ax.get_yaxis().set_visible(False)\n",
    "    allTraj=get_positions_array_beginning(data)\n",
    "    time=(np.arange(allTraj.shape[1])/data.cameraSamplingRate)+data.cameraToTreadmillDelay\n",
    "    ax.set_xlim([time[0],10])\n",
    "    ax.set_ylim([0,90])\n",
    "    im = ax.plot(time[:1],allTraj[trial,:1],'k')\n",
    "    \n",
    "    fig.set_size_inches([5,5])\n",
    "\n",
    "\n",
    "    tight_layout()\n",
    "\n",
    "\n",
    "    def update_img(n):\n",
    "        im = ax.plot(time[:n],allTraj[trial,:n],color='k')\n",
    "        return im\n",
    "\n",
    "    #legend(loc=0)\n",
    "    ani = animation.FuncAnimation(fig,update_img,len(time),interval=np.median(np.diff(time))*1000,blit=True)\n",
    "    writer = animation.writers['ffmpeg'](fps=data.cameraSamplingRate,codec=None)\n",
    "\n",
    "    ani.save('/home/david/Mostafa/demo.mp4',writer=writer,dpi=dpi)\n",
    "    return ani\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "session=\"Rat167_2018_01_09_15_14\"\n",
    "data=Data(root,session[:6],session,defaultParam,redoPreprocess=False)\n",
    "ani_frame(data,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### multiple trials\n",
    "works if all the trials are OK, (fix the videofile length problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpi = 50\n",
    "\n",
    "def ani_frame(data,trials=[0]):\n",
    "    fig = plt.figure()\n",
    "    fig.set_size_inches([5,5])\n",
    "    ax = fig.add_subplot(111)\n",
    "    allTraj=get_positions_array_beginning(data)\n",
    "    #control for the extra 1 s in the begining of the video\n",
    "    allTraj=np.concatenate((np.ones((allTraj.shape[0],int(data.cameraToTreadmillDelay*data.cameraSamplingRate)))*np.nan,allTraj),axis=1)\n",
    "    time=np.arange(allTraj.shape[1])/data.cameraSamplingRate-data.cameraToTreadmillDelay\n",
    "    ax.set_xlim([0,10])\n",
    "    ax.set_ylim([0,90])\n",
    "    cmap = plt.get_cmap('cool')\n",
    "    colors = [cmap(i) for i in np.linspace(0, 1, len(trials))]\n",
    "    \n",
    "    im = ax.plot(time[:1],allTraj[trials[0],:1],color=colors[0])\n",
    "    tight_layout()\n",
    "\n",
    "\n",
    "    def update_img(IN):\n",
    "        global im\n",
    "        n,trial,i=IN\n",
    "        if n <= int((data.entranceTime[trial]+data.cameraToTreadmillDelay)*data.cameraSamplingRate):\n",
    "            im = ax.plot(time[:n],allTraj[trial,:n],color=colors[i])\n",
    "        return im\n",
    "\n",
    "    frames=[(t,trial,i) for i,trial in enumerate(trials) for t in range(int((data.entranceTime[trial]+data.interTrialDuration[trial]+data.cameraToTreadmillDelay)*data.cameraSamplingRate))]\n",
    "    ani = animation.FuncAnimation(fig=fig,func=update_img,frames=frames,interval=1e3/data.cameraSamplingRate)\n",
    "    writer = animation.writers['ffmpeg'](fps=data.cameraSamplingRate,codec=None)\n",
    "\n",
    "    ani.save('/home/david/Mostafa/demo.mp4',writer=writer,dpi=dpi)\n",
    "    print(\"Done!\")\n",
    "    return ani\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session=\"Rat167_2018_01_09_15_14\"\n",
    "data=Data(root,session[:6],session,defaultParam,redoPreprocess=False)\n",
    "ani=ani_frame(data,trials=[2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at first few trials of each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overriding following function\n",
    "def compute_or_read_stats(data, PerfParamToPlot, \n",
    "                          saveAsPickle=True, pickleName=\"behaviorStats.p\",redo=False):\n",
    "    \"\"\"\n",
    "    Function to calculate the performance parameters of a single session\n",
    "    \"\"\"\n",
    "    pathPickle=os.path.join(data.analysisPath,pickleName)\n",
    "    if os.path.exists(pathPickle) and not redo:\n",
    "        with open(pathPickle,\"rb\") as f:\n",
    "            result=pickle.load(f)\n",
    "            if set(PerfParamToPlot).issubset(set(result.keys())):\n",
    "                result={key:result[key] for key in result.keys() if key in PerfParamToPlot}\n",
    "                return result\n",
    "            else:\n",
    "                params=list(set(PerfParamToPlot).difference(set(result.keys())))\n",
    "                result={key:result[key] for key in result.keys() if key not in params}\n",
    "    else:\n",
    "        params=PerfParamToPlot\n",
    "        result={}\n",
    "    for param in params:\n",
    "        try:\n",
    "            if param==\"% good trials\":\n",
    "                #percentage of good trials\n",
    "                result[param]=np.round(len(data.goodTrials)/(float(data.nTrial)+0) *100)\n",
    "            elif param==\"% good trials on last 40\":\n",
    "                #percentage of good trials in the 40 last trials\n",
    "                last40GoodTrial=[trial for trial in data.goodTrials if trial>(data.nTrial-41)]\n",
    "                result[param]=np.round(len(last40GoodTrial)/40.0 *100)\n",
    "            elif param==\"percentile entrance time\":\n",
    "                #percentile entrance time\n",
    "                realEntranceTimes=data.entranceTime[data.entranceTime<data.maxTrialDuration]\n",
    "                if len(realEntranceTimes)>0:\n",
    "                    entranceTimeP=np.nanpercentile(realEntranceTimes,[10,25,50,75,90])\n",
    "                    result[param]=entranceTimeP\n",
    "                else:\n",
    "                    result[param]=np.full(5,data.maxTrialDuration[0])\n",
    "            elif param==\"median entrance time (sec)\":\n",
    "                #median and std of entrance time\n",
    "                result[param]=np.nanmedian(data.entranceTime[data.entranceTime<data.maxTrialDuration])\n",
    "            elif param==\"standard deviation of entrance time\":    \n",
    "                result[param]=np.nanstd(data.entranceTime)\n",
    "            elif param==\"mean entrance time (sec)\":\n",
    "                result[param]=np.nanmean(data.entranceTime[data.entranceTime<data.maxTrialDuration])\n",
    "\n",
    "                #median correlation trajectories\n",
    "                #result[\"median correlation of trajectories\"]=plot_correlation_position(data,onlyGood=True)\n",
    "            elif param==\"mean entrance times for first N\":\n",
    "                et=data.entranceTime[:10] #N\n",
    "                result[param]=np.nanmean(et[et<np.nanmean(data.maxTrialDuration)])\n",
    "            elif param==\"spearman entrance time\":\n",
    "                #correlation entrance time\n",
    "                result[param]=plot_correlation_entrance_time(data)\n",
    "            elif param==\"time running forward\":\n",
    "                #proportion of time running forward\n",
    "                areaUnderCurve=plot_proportionTimeRunningForward_TrajEnd(data,binSize=1,minSpeed=-20,maxSpeed=120,smoothSpeed=0.3,onlyGood=False,highSpeed=None)\n",
    "                result[param]=areaUnderCurve\n",
    "            elif param==\"timerunningforwardGoodTrials\":\n",
    "                #proportion of time running forward for good trials\n",
    "                areaUnderCurve=plot_proportionTimeRunningForward_TrajEnd(data,binSize=1,minSpeed=-20,maxSpeed=120,smoothSpeed=0.3,onlyGood=True,highSpeed=None)\n",
    "                result[param]=areaUnderCurve\n",
    "            elif param==\"Forward Speed\":\n",
    "                #Forward Speed\n",
    "                result[param]=plot_mean_forwardSpeed(data,smoothSpeed=0.3,onlyGood=False)\n",
    "                plt.close()\n",
    "            elif param==\"Forward Speed Vs TreadmillSpeed\":\n",
    "                #Forward Speed vs TreadmillSpeed\n",
    "                result[param]=plot_mean_forwardSpeedVsTreadmillSpeed(data,smoothSpeed=0.3,onlyGood=False)\n",
    "                plt.close()\n",
    "            elif param==\"Forward Speed good trials\":\n",
    "                #Forward Speed for good trials\n",
    "                result[param]=plot_mean_forwardSpeed(data,smoothSpeed=0.3,onlyGood=True)\n",
    "                plt.close()\n",
    "            elif param==\"Tortuosity\":\n",
    "                #Tortuosity  and StraightSpeedForward\n",
    "                SessionTortuosity,SessionStraightSpeed=plot_Tortuosity(data, onlyGood=False)\n",
    "                plt.close()\n",
    "                result[param]=SessionTortuosity\n",
    "            elif param==\"Straight Speed Forward\":\n",
    "                SessionTortuosity,SessionStraightSpeed=plot_Tortuosity(data, onlyGood=False)\n",
    "                plt.close()\n",
    "                result[param]=SessionStraightSpeed\n",
    "            elif param==\"Trajectory Correlation\":\n",
    "                #Trajectory Correlation\n",
    "                SessionCorrelationTrajectory= plot_correlation_position(data,onlyGood=False,raw=False)\n",
    "                plt.close()\n",
    "                result[param]=SessionCorrelationTrajectory\n",
    "            elif param==\"Trajectory Correlation good trials\":\n",
    "                #Trajectory Correlation for good trials\n",
    "                SessionCorrelationTrajectory= plot_correlation_position(data,onlyGood=True,raw=False)\n",
    "                plt.close()\n",
    "                result[param]=SessionCorrelationTrajectory\n",
    "            elif param==\"Std from goaltime\":\n",
    "                #Std from goaltime\n",
    "                result[param]=std_from_goaltime(data)\n",
    "            elif param==\"Delivered Reward Ratio\":\n",
    "                result[param]=data.deliveredRewardRatio\n",
    "            elif param==\"Number of missed trials\":\n",
    "                result[param]=sum(data.entranceTime<0.1)+sum(data.entranceTime>data.maxTrialDuration-1)\n",
    "            elif param==\"Mean Pairwise RMSE\":\n",
    "                m,_=plot_rmse(data,alignedOnBegining=True,onlyGood=False,raw=False)\n",
    "                result[param]=m\n",
    "            elif param==\"Entropy\":\n",
    "                _,H=plot_trajectory_PDF(data,TimeRes=.5,PosRes=5,onlyGood=False)\n",
    "                plt.close()\n",
    "                result[param]=H\n",
    "            elif param==\"Run Distance\":\n",
    "                dis=plot_run_distance(data,onlyGood=False,raw=False)\n",
    "                plt.close()\n",
    "                result[param]=np.mean(dis)\n",
    "            elif param==\"Forward Running Speed\":\n",
    "                result[param]=np.mean(plot_forward_running_speed(data,minXBack=55,onlyGood=False))\n",
    "                plt.close()\n",
    "            elif param==\"Lick Onset Delay\":\n",
    "                lickTrdStop=plot_lick_raster(data,plot_inset=False)\n",
    "                plt.close()\n",
    "                posLicks=[np.array(lick)[np.array(lick)>0] for i,lick in enumerate(lickTrdStop)\n",
    "                          if len(lick)>0 and i in data.goodTrials]\n",
    "                firstLick=[i[0] for i in posLicks if len(i)>0]\n",
    "                result[param]=np.mean(firstLick)\n",
    "        except Exception as e:\n",
    "            print(repr(e))\n",
    "            result[param]=np.nan\n",
    "    \n",
    "    if saveAsPickle:\n",
    "        with open(pathPickle, 'wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "\n",
    "    profile1={'Type':'Good',\n",
    "             'rewardType':'Progressive',\n",
    "             'initialSpeed':'10',\n",
    "             'Speed':'10',\n",
    "             'Tag':['Control']\n",
    "             }\n",
    "    profile2={'Type':'Good',\n",
    "             'rewardType':'Progressive',\n",
    "#              'initialSpeed':'10',\n",
    "#              'Speed':'10',\n",
    "             'Tag':['Early-Lesion_GPi']\n",
    "             }\n",
    "    animalList1=batch_get_animal_list(root,profile1)\n",
    "    animalList2=batch_get_animal_list(root,profile2)\n",
    "    #different conrtol groups\n",
    "    \n",
    "\n",
    "    groups={\n",
    "        \"group1\":(cm.Greys,\"black\",animalList1,profile1),\n",
    "        \"group2\":(cm.Reds ,\"red\"  ,animalList2,profile2),\n",
    "        }\n",
    "\n",
    "    print(\"animal lists:\\n\",animalList1,'\\n',animalList2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "\n",
    "    TaskParamToPlot=[\"% good trials on last 40\",\"percentile entrance time\",\n",
    "                \"Forward Speed Vs TreadmillSpeed\",\"Tortuosity\",\"standard deviation of entrance time\",\"Trajectory Correlation\"]\n",
    "    TaskParamToPlot=[\"mean entrance times for first N\",\"percentile entrance time\"]\n",
    "\n",
    "    stop_dayPlot =15\n",
    "    fullLegend=False\n",
    "\n",
    "    allResults,colors,colorGroup=plot_mean_subgroup_animal(root,groups,parameter=defaultParam,redo=True,stop_dayPlot=stop_dayPlot,TaskParamToPlot=TaskParamToPlot,fullLegend=fullLegend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ET vs #Trial correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AnimalProfile={'Type':'Good',\n",
    "     'rewardType':'Progressive',\n",
    "     'initialSpeed':'10',\n",
    "     'Speed':['10'],\n",
    "     'Tag':'Control'\n",
    "              }\n",
    "animalList=batch_get_animal_list(root,AnimalProfile)\n",
    "animalList=['Rat265']\n",
    "sessionDict=batch_get_session_list(root,animalList,profile=AnimalProfile)\n",
    "\n",
    "SESSION_LIMIT=-55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trials vs ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SESSION_LIMIT >0:\n",
    "    tmp=sorted(sessionDict['Sessions'])[:SESSION_LIMIT]\n",
    "else:\n",
    "    tmp=sorted(sessionDict['Sessions'])[SESSION_LIMIT:]\n",
    "\n",
    "corrList=[]\n",
    "pList=[]\n",
    "for session in tmp:\n",
    "    data=Data(root,session[:6],session,defaultParam,redoPreprocess=False)\n",
    "    r,p=scipy.stats.spearmanr(data.trials[:], b=data.entranceTime[data.trials])\n",
    "    corrList.append(r)\n",
    "    pList.append(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trial vs forward speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SESSION_LIMIT >0:\n",
    "    tmp=sorted(sessionDict['Sessions'])[:SESSION_LIMIT]\n",
    "else:\n",
    "    tmp=sorted(sessionDict['Sessions'])[SESSION_LIMIT:]\n",
    "\n",
    "corrList=[]\n",
    "pList=[]\n",
    "\n",
    "\n",
    "for session in tmp:\n",
    "    ValuesSessionRatio=[]\n",
    "    data=Data(root,session[:6],session,defaultParam,redoPreprocess=False)\n",
    "    treadmillSpeed = np.nanmean(data.treadmillSpeed)\n",
    "    for trial in data.trials:\n",
    "        if trial in data.goodTrials:\n",
    "            speed,time=get_speed_treadmillON(data,trial,sigmaSpeed=0.3)\n",
    "            MeanSpeed=np.nanmean(speed[speed>treadmillSpeed])\n",
    "            ratio=MeanSpeed/treadmillSpeed\n",
    "            ValuesSessionRatio.append(ratio)\n",
    "    \n",
    "    r,p=scipy.stats.spearmanr(a=data.goodTrials[], b=ValuesSessionRatio[])\n",
    "    corrList.append(r)\n",
    "    pList.append(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax=plt.subplot(111)\n",
    "ax.plot(corrList,'-b')\n",
    "for i,p in enumerate(pList):\n",
    "    if 0.01<p<0.05:\n",
    "        m='v'\n",
    "    elif 0.001<p<0.01:\n",
    "        m='s'\n",
    "    elif p< 0.001:\n",
    "        m='*'\n",
    "    else:\n",
    "        m='o'\n",
    "    ax.plot(i,corrList[i],marker=m,color='b',markersize=10)\n",
    "ax.set_ylabel(\"correlation\")\n",
    "ax.set_xlabel(\"Session\")\n",
    "ax.set_title(animalList);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### group analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overriding following function\n",
    "def compute_or_read_stats(data, PerfParamToPlot, \n",
    "                          saveAsPickle=True, pickleName=\"behaviorStats.p\",redo=False):\n",
    "    \"\"\"\n",
    "    Function to calculate the performance parameters of a single session\n",
    "    \"\"\"\n",
    "    pathPickle=os.path.join(data.analysisPath,pickleName)\n",
    "    if os.path.exists(pathPickle) and not redo:\n",
    "        with open(pathPickle,\"rb\") as f:\n",
    "            result=pickle.load(f)\n",
    "            if set(PerfParamToPlot).issubset(set(result.keys())):\n",
    "                result={key:result[key] for key in result.keys() if key in PerfParamToPlot}\n",
    "                return result\n",
    "            else:\n",
    "                params=list(set(PerfParamToPlot).difference(set(result.keys())))\n",
    "                result={key:result[key] for key in result.keys() if key not in params}\n",
    "    else:\n",
    "        params=PerfParamToPlot\n",
    "        result={}\n",
    "    for param in params:\n",
    "        try:\n",
    "            if param==\"% good trials\":\n",
    "                #percentage of good trials\n",
    "                result[param]=np.round(len(data.goodTrials)/(float(data.nTrial)+0) *100)\n",
    "            elif param==\"% good trials on last 40\":\n",
    "                #percentage of good trials in the 40 last trials\n",
    "                last40GoodTrial=[trial for trial in data.goodTrials if trial>(data.nTrial-41)]\n",
    "                result[param]=np.round(len(last40GoodTrial)/40.0 *100)\n",
    "            elif param==\"percentile entrance time\":\n",
    "                #percentile entrance time\n",
    "                realEntranceTimes=data.entranceTime[data.entranceTime<data.maxTrialDuration]\n",
    "                if len(realEntranceTimes)>0:\n",
    "                    entranceTimeP=np.nanpercentile(realEntranceTimes,[10,25,50,75,90])\n",
    "                    result[param]=entranceTimeP\n",
    "                else:\n",
    "                    result[param]=np.full(5,data.maxTrialDuration[0])\n",
    "            elif param==\"median entrance time (sec)\":\n",
    "                #median and std of entrance time\n",
    "                result[param]=np.nanmedian(data.entranceTime[data.entranceTime<data.maxTrialDuration])\n",
    "            elif param==\"standard deviation of entrance time\":    \n",
    "                result[param]=np.nanstd(data.entranceTime)\n",
    "            elif param==\"mean entrance time (sec)\":\n",
    "                result[param]=np.nanmean(data.entranceTime[data.entranceTime<data.maxTrialDuration])\n",
    "\n",
    "                #median correlation trajectories\n",
    "                #result[\"median correlation of trajectories\"]=plot_correlation_position(data,onlyGood=True)\n",
    "            elif param==\"mean entrance times for first N\":\n",
    "                et=data.entranceTime[:10] #N\n",
    "                result[param]=np.nanmean(et[et<np.nanmean(data.maxTrialDuration)])\n",
    "            elif param==\"spearman entrance time\":\n",
    "                #correlation entrance time\n",
    "                result[param]=plot_correlation_entrance_time(data)\n",
    "            elif param==\"trialVsEntranceTimeSpearman\":\n",
    "                result[param],_=scipy.stats.spearmanr(a=data.trials, b=data.entranceTime[data.trials])\n",
    "            elif param==\"time running forward\":\n",
    "                #proportion of time running forward\n",
    "                areaUnderCurve=plot_proportionTimeRunningForward_TrajEnd(data,binSize=1,minSpeed=-20,maxSpeed=120,smoothSpeed=0.3,onlyGood=False,highSpeed=None)\n",
    "                result[param]=areaUnderCurve\n",
    "            elif param==\"timerunningforwardGoodTrials\":\n",
    "                #proportion of time running forward for good trials\n",
    "                areaUnderCurve=plot_proportionTimeRunningForward_TrajEnd(data,binSize=1,minSpeed=-20,maxSpeed=120,smoothSpeed=0.3,onlyGood=True,highSpeed=None)\n",
    "                result[param]=areaUnderCurve\n",
    "            elif param==\"Forward Speed\":\n",
    "                #Forward Speed\n",
    "                result[param]=plot_mean_forwardSpeed(data,smoothSpeed=0.3,onlyGood=False)\n",
    "                plt.close()\n",
    "            elif param==\"Forward Speed Vs TreadmillSpeed\":\n",
    "                #Forward Speed vs TreadmillSpeed\n",
    "                result[param]=plot_mean_forwardSpeedVsTreadmillSpeed(data,smoothSpeed=0.3,onlyGood=False)\n",
    "                plt.close()\n",
    "            elif param==\"Forward Speed good trials\":\n",
    "                #Forward Speed for good trials\n",
    "                result[param]=plot_mean_forwardSpeed(data,smoothSpeed=0.3,onlyGood=True)\n",
    "                plt.close()\n",
    "            elif param==\"Tortuosity\":\n",
    "                #Tortuosity  and StraightSpeedForward\n",
    "                SessionTortuosity,SessionStraightSpeed=plot_Tortuosity(data, onlyGood=False)\n",
    "                plt.close()\n",
    "                result[param]=SessionTortuosity\n",
    "            elif param==\"Straight Speed Forward\":\n",
    "                SessionTortuosity,SessionStraightSpeed=plot_Tortuosity(data, onlyGood=False)\n",
    "                plt.close()\n",
    "                result[param]=SessionStraightSpeed\n",
    "            elif param==\"Trajectory Correlation\":\n",
    "                #Trajectory Correlation\n",
    "                SessionCorrelationTrajectory= plot_correlation_position(data,onlyGood=False,raw=False)\n",
    "                plt.close()\n",
    "                result[param]=SessionCorrelationTrajectory\n",
    "            elif param==\"Trajectory Correlation good trials\":\n",
    "                #Trajectory Correlation for good trials\n",
    "                SessionCorrelationTrajectory= plot_correlation_position(data,onlyGood=True,raw=False)\n",
    "                plt.close()\n",
    "                result[param]=SessionCorrelationTrajectory\n",
    "            elif param==\"Std from goaltime\":\n",
    "                #Std from goaltime\n",
    "                result[param]=std_from_goaltime(data)\n",
    "            elif param==\"Delivered Reward Ratio\":\n",
    "                result[param]=data.deliveredRewardRatio\n",
    "            elif param==\"Number of missed trials\":\n",
    "                result[param]=sum(data.entranceTime<0.1)+sum(data.entranceTime>data.maxTrialDuration-1)\n",
    "            elif param==\"Mean Pairwise RMSE\":\n",
    "                m,_=plot_rmse(data,alignedOnBegining=True,onlyGood=False,raw=False)\n",
    "                result[param]=m\n",
    "            elif param==\"Entropy\":\n",
    "                _,H=plot_trajectory_PDF(data,TimeRes=.5,PosRes=5,onlyGood=False)\n",
    "                plt.close()\n",
    "                result[param]=H\n",
    "            elif param==\"Run Distance\":\n",
    "                dis=plot_run_distance(data,onlyGood=False,raw=False)\n",
    "                plt.close()\n",
    "                result[param]=np.mean(dis)\n",
    "            elif param==\"Forward Running Speed\":\n",
    "                result[param]=np.mean(plot_forward_running_speed(data,minXBack=55,onlyGood=False))\n",
    "                plt.close()\n",
    "            elif param==\"Lick Onset Delay\":\n",
    "                lickTrdStop=plot_lick_raster(data,plot_inset=False)\n",
    "                plt.close()\n",
    "                posLicks=[np.array(lick)[np.array(lick)>0] for i,lick in enumerate(lickTrdStop)\n",
    "                          if len(lick)>0 and i in data.goodTrials]\n",
    "                firstLick=[i[0] for i in posLicks if len(i)>0]\n",
    "                result[param]=np.mean(firstLick)\n",
    "        except Exception as e:\n",
    "            print(repr(e))\n",
    "            result[param]=np.nan\n",
    "    \n",
    "    if saveAsPickle:\n",
    "        with open(pathPickle, 'wb') as f:\n",
    "            pickle.dump(result, f)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "\n",
    "    profile1={'Type':'Good',\n",
    "             'rewardType':'Progressive',\n",
    "             'initialSpeed':'10',\n",
    "             'Speed':'10',\n",
    "             'Tag':['Control']\n",
    "             }\n",
    "    profile2={'Type':'Good',\n",
    "             'rewardType':'Progressive',\n",
    "             'initialSpeed':'10',\n",
    "             'Speed':'10',\n",
    "             'Tag':['Early-Lesion_DLS']\n",
    "             }\n",
    "    animalList1=batch_get_animal_list(root,profile1)\n",
    "    animalList2=batch_get_animal_list(root,profile2)\n",
    "    #different conrtol groups\n",
    "    \n",
    "\n",
    "    groups={\n",
    "        \"group1\":(cm.Greys,\"black\",animalList1,profile1),\n",
    "        \"group2\":(cm.Reds ,\"red\"  ,animalList2,profile2),\n",
    "        }\n",
    "\n",
    "    print(\"animal lists:\\n\",animalList1,'\\n',animalList2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if \"__file__\" not in dir():\n",
    "\n",
    "    TaskParamToPlot=[\"% good trials on last 40\",\"percentile entrance time\",\n",
    "                \"Forward Speed Vs TreadmillSpeed\",\"Tortuosity\",\"standard deviation of entrance time\",\"Trajectory Correlation\"]\n",
    "    TaskParamToPlot=[\"trialVsEntranceTimeSpearman\",\"percentile entrance time\"]\n",
    "\n",
    "    stop_dayPlot =30\n",
    "    fullLegend=False\n",
    "\n",
    "    allResults,colors,colorGroup=plot_mean_subgroup_animal(root,groups,parameter=defaultParam,redo=True,stop_dayPlot=stop_dayPlot,TaskParamToPlot=TaskParamToPlot,fullLegend=fullLegend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TaskParamToPlot=[\"trialVsEntranceTimeSpearman\"]\n",
    "\n",
    "stop_dayPlot =30\n",
    "fullLegend=False\n",
    "n_iteration=1e3\n",
    "\n",
    "a=plot_mean_animals(root,groups,n_iteration=n_iteration,\n",
    "                    parameter=defaultParam,redo=False,stop_dayPlot=stop_dayPlot,TaskParamToPlot=TaskParamToPlot,fullLegend=fullLegend,title='')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
